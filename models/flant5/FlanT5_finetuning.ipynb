{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6ad617-ac7d-43fc-85f3-ddb8ee526df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.39.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: pytorch_lightning in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (4.10.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytorch_lightning) (0.11.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (58.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (3.13.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.6)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: seqeval in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.22.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seqeval) (1.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: tensorboardX in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboardX) (24.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\lawfu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboardX) (5.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "#   this is the huggingface transformer module\n",
    "#   https://github.com/huggingface/transformers/tree/main\n",
    "#   https://github.com/huggingface/transformers/blob/main/src/transformers/models/t5/tokenization_t5.py\n",
    "!pip install pytorch_lightning\n",
    "!pip install sentencepiece datasets seqeval\n",
    "#   Fixes error: T5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\n",
    "#   installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
    "#   that match your environment. Please note that you may need to restart your runtime after installation.\n",
    "!pip install tensorboardX\n",
    "#   Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, \n",
    "#   due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use \n",
    "#   `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. \n",
    "#   Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebe030e-1fd7-4c5a-8841-bb586857b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc10d6f-0f9b-4e74-a413-a369a0d4b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    MT5ForConditionalGeneration,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9715ea5e-5d18-4a37-a2b5-29b8bbabf525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show entire column instead of truncating it\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9469a03-5398-4109-a618-29b339ba761d",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88167fa2-b3d8-4b7a-83ee-569ddab2b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to CustomDataset.py to fix the error:\n",
    "# --> self = reduction.pickle.load(from_parent)\n",
    "#     AttributeError: Can't get attribute 'CustomDataset' on <module '__main__' (built-in)>\n",
    "# see also https://github.com/Lightning-AI/pytorch-lightning/discussions/15350\n",
    "\n",
    "from CustomDataset import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab35e4d0-8ce1-4bc3-a84a-c81afdc05e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetOptions.DBPEDIA\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class DatasetOptions(Enum):\n",
    "    WIKIDATA = 'wikidata', # Text2KG Benchmark training dataset 1\n",
    "    DBPEDIA = 'dbpedia', # Text2KG Benchmark training dataset 2\n",
    "    AMAZON = 'amazon' # unlabeled\n",
    "\n",
    "TRAINING_DATASET = DatasetOptions.DBPEDIA\n",
    "print(TRAINING_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4ee2ca-f55a-4f43-84a4-944eb7adbb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads into one dataframe all the .jsonl files in the file_list located under the given folder\n",
    "def load_dataframe_from_jsonl(folder, file_list):\n",
    "    file = folder + file_list[0]\n",
    "    \n",
    "    # open the first file and read it into a dataframe\n",
    "    with open(file, \"r\"):\n",
    "        df = pd.read_json(file, lines=True)\n",
    "        \n",
    "    # append the rest of the files into the same dataframe\n",
    "    for filename in file_list:\n",
    "        if filename == file_list[0]:\n",
    "            # we already added this one\n",
    "            continue\n",
    "        file2 = folder + filename\n",
    "        df2 = pd.read_json(file2, lines=True)\n",
    "        df = pd.concat([df, df2])\n",
    "    df.reset_index(drop=True, inplace=True) # use one continuous index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704c5692-a251-4f61-ad2a-6918d67cb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage: tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "#        input_dataset = tokenize_dataset(tokenizer=tokenizer, dataset=dataset, type_path=\"train\")\n",
    "#\n",
    "# type_path: torch.Dataset type_path parameter. \"train\", \"test\", \"val\"\n",
    "def tokenize_dataset(tokenizer, dataset, type_path):\n",
    "    custom_dataset = CustomDataset(tokenizer=tokenizer, dataset=dataset, type_path=type_path)\n",
    "    if type_path == \"train\": # Only need to tokenize & pad training data\n",
    "        # dunno what this is doing\n",
    "        for i in range(len(custom_dataset)):\n",
    "            _ = custom_dataset[i]\n",
    "        tokenized_dataset = custom_dataset[0]\n",
    "        print(tokenizer.decode(tokenized_dataset[\"source_ids\"], skip_special_tokens=False))\n",
    "        print(tokenizer.decode(tokenized_dataset[\"target_ids\"], skip_special_tokens=False))\n",
    "        return custom_dataset\n",
    "    else:\n",
    "        return custom_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760023c-7a95-4766-84be-b179c9513a6d",
   "metadata": {},
   "source": [
    "## Text2KG Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793c33a-75a1-46ac-b4ae-c50757ccd16a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DBPedia-webnlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada8da3b-8021-4e5c-bdc2-dea2163b22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative folder path. Expects Text2KGBench-main folder to be at the same level\n",
    "# as this .ipynb file\n",
    "dbpedia_folder = 'Text2KGBench-main/data/dbpedia_webnlg/' #baselines/prompts/\n",
    "dbpedia_subfolder_train = 'train/'\n",
    "dbpedia_subfolder_test = 'ground_truth/'\n",
    "dbpedia_filenames = [\n",
    "'ont_1_university',\n",
    "'ont_2_musicalwork',\n",
    "'ont_3_airport',\n",
    "'ont_4_building',\n",
    "'ont_5_athlete',\n",
    "'ont_6_politician',\n",
    "'ont_7_company',\n",
    "'ont_8_celestialbody',\n",
    "'ont_9_astronaut',\n",
    "'ont_10_comicscharacter',\n",
    "'ont_11_meanoftransportation',\n",
    "'ont_12_monument',\n",
    "'ont_13_food',\n",
    "'ont_14_writtenwork',\n",
    "'ont_15_sportsteam',\n",
    "'ont_16_city',\n",
    "'ont_17_artist',\n",
    "'ont_18_scientist',\n",
    "'ont_19_film',\n",
    "]\n",
    "dbpedia_ender_prompts = '_prompts.json'\n",
    "dbpedia_ender_train = '_train.jsonl'\n",
    "dbpedia_ender_test = '_ground_truth.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5384a368-95e3-46fc-a2f5-eed7a6d4d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dbpedia_train = load_dataframe_from_jsonl(\n",
    "    dbpedia_folder + dbpedia_subfolder_train\n",
    "    ,[s + dbpedia_ender_train for s in dbpedia_filenames]\n",
    ")\n",
    "df_dbpedia_test = load_dataframe_from_jsonl(\n",
    "    dbpedia_folder + dbpedia_subfolder_test\n",
    "    ,[s + dbpedia_ender_test for s in dbpedia_filenames]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c12f20e2-36a7-4b39-839d-72040ac7e65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sent</th>\n",
       "      <th>triples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ont_1_university_train_1</td>\n",
       "      <td>1 Decembrie 1918 University is located in Alba, Romania and its Latin name is \"Universitas Apulensis\".</td>\n",
       "      <td>[{'sub': '1_Decembrie_1918_University', 'rel': 'latinName', 'obj': '\"Universitas Apulensis\"'}, {'sub': '1_Decembrie_1918_University', 'rel': 'country', 'obj': 'Romania'}, {'sub': '1_Decembrie_1918_University', 'rel': 'state', 'obj': 'Alba'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ont_1_university_train_2</td>\n",
       "      <td>The 1 Decembrie 1918 University is located in Alba Iulia, Alba. Its nickname is Uab.</td>\n",
       "      <td>[{'sub': '1_Decembrie_1918_University', 'rel': 'nickname', 'obj': 'Uab'}, {'sub': '1_Decembrie_1918_University', 'rel': 'city', 'obj': 'Alba_Iulia'}, {'sub': '1_Decembrie_1918_University', 'rel': 'state', 'obj': 'Alba'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ont_1_university_train_3</td>\n",
       "      <td>The nickname of the 1 Decembrie 1918 University is Uab. The latin name is \"Universitas Apulensis\" and the rector is Breaz Valer Daniel.</td>\n",
       "      <td>[{'sub': '1_Decembrie_1918_University', 'rel': 'nickname', 'obj': 'Uab'}, {'sub': '1_Decembrie_1918_University', 'rel': 'rector', 'obj': '\"Breaz Valer Daniel\"'}, {'sub': '1_Decembrie_1918_University', 'rel': 'latinName', 'obj': '\"Universitas Apulensis\"'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ont_1_university_train_4</td>\n",
       "      <td>1 Decembrie 1918 University is located in Alba Iulia, Romania and its rector is Breaz Valer Daniel.</td>\n",
       "      <td>[{'sub': '1_Decembrie_1918_University', 'rel': 'rector', 'obj': '\"Breaz Valer Daniel\"'}, {'sub': '1_Decembrie_1918_University', 'rel': 'city', 'obj': 'Alba_Iulia'}, {'sub': '1_Decembrie_1918_University', 'rel': 'country', 'obj': 'Romania'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ont_1_university_train_5</td>\n",
       "      <td>The Accademia di Architettura di Mendrisio is in Mendrisio. It has 600 students and an academic staff of 100.</td>\n",
       "      <td>[{'sub': 'Accademia_di_Architettura_di_Mendrisio', 'rel': 'city', 'obj': 'Mendrisio'}, {'sub': 'Accademia_di_Architettura_di_Mendrisio', 'rel': 'numberOfStudents', 'obj': '600'}, {'sub': 'Accademia_di_Architettura_di_Mendrisio', 'rel': 'academicStaffSize', 'obj': '100'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  ont_1_university_train_1   \n",
       "1  ont_1_university_train_2   \n",
       "2  ont_1_university_train_3   \n",
       "3  ont_1_university_train_4   \n",
       "4  ont_1_university_train_5   \n",
       "\n",
       "                                                                                                                                      sent  \\\n",
       "0                                   1 Decembrie 1918 University is located in Alba, Romania and its Latin name is \"Universitas Apulensis\".   \n",
       "1                                                     The 1 Decembrie 1918 University is located in Alba Iulia, Alba. Its nickname is Uab.   \n",
       "2  The nickname of the 1 Decembrie 1918 University is Uab. The latin name is \"Universitas Apulensis\" and the rector is Breaz Valer Daniel.   \n",
       "3                                      1 Decembrie 1918 University is located in Alba Iulia, Romania and its rector is Breaz Valer Daniel.   \n",
       "4                            The Accademia di Architettura di Mendrisio is in Mendrisio. It has 600 students and an academic staff of 100.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           triples  \n",
       "0                                [{'sub': '1_Decembrie_1918_University', 'rel': 'latinName', 'obj': '\"Universitas Apulensis\"'}, {'sub': '1_Decembrie_1918_University', 'rel': 'country', 'obj': 'Romania'}, {'sub': '1_Decembrie_1918_University', 'rel': 'state', 'obj': 'Alba'}]  \n",
       "1                                                     [{'sub': '1_Decembrie_1918_University', 'rel': 'nickname', 'obj': 'Uab'}, {'sub': '1_Decembrie_1918_University', 'rel': 'city', 'obj': 'Alba_Iulia'}, {'sub': '1_Decembrie_1918_University', 'rel': 'state', 'obj': 'Alba'}]  \n",
       "2                  [{'sub': '1_Decembrie_1918_University', 'rel': 'nickname', 'obj': 'Uab'}, {'sub': '1_Decembrie_1918_University', 'rel': 'rector', 'obj': '\"Breaz Valer Daniel\"'}, {'sub': '1_Decembrie_1918_University', 'rel': 'latinName', 'obj': '\"Universitas Apulensis\"'}]  \n",
       "3                                 [{'sub': '1_Decembrie_1918_University', 'rel': 'rector', 'obj': '\"Breaz Valer Daniel\"'}, {'sub': '1_Decembrie_1918_University', 'rel': 'city', 'obj': 'Alba_Iulia'}, {'sub': '1_Decembrie_1918_University', 'rel': 'country', 'obj': 'Romania'}]  \n",
       "4  [{'sub': 'Accademia_di_Architettura_di_Mendrisio', 'rel': 'city', 'obj': 'Mendrisio'}, {'sub': 'Accademia_di_Architettura_di_Mendrisio', 'rel': 'numberOfStudents', 'obj': '600'}, {'sub': 'Accademia_di_Architettura_di_Mendrisio', 'rel': 'academicStaffSize', 'obj': '100'}]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dbpedia_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2bc66-a150-4e84-b638-cfd81e188d16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Wikidata Tekgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff6c8493-8f30-4f19-b6ed-a4d0a737e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_folder = 'Text2KGBench-main/data/wikidata_tekgen/'\n",
    "wikidata_subfolder_prompts = 'baselines/prompts/'\n",
    "wikidata_subfolder_train = 'train/'\n",
    "wikidata_subfolder_test = 'ground_truth/'\n",
    "wikidata_filenames = [\n",
    "'ont_1_movie',\n",
    "'ont_2_music',\n",
    "'ont_3_sport',\n",
    "'ont_4_book',\n",
    "'ont_5_military',\n",
    "'ont_6_computer',\n",
    "'ont_7_space',\n",
    "'ont_8_politics',\n",
    "'ont_9_nature',\n",
    "'ont_10_culture'\n",
    "]\n",
    "wikidata_ender_prompts = '_prompts.json'\n",
    "wikidata_ender_train = '_train.jsonl'\n",
    "wikidata_ender_test = '_ground_truth.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d82467-c0fd-4e13-88f0-cba3403e1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikidata_train = load_dataframe_from_jsonl(\n",
    "    wikidata_folder + wikidata_subfolder_train\n",
    "    ,[s + wikidata_ender_train for s in wikidata_filenames]\n",
    ")\n",
    "\n",
    "df_wikidata_test = load_dataframe_from_jsonl(\n",
    "    wikidata_folder + wikidata_subfolder_test\n",
    "    ,[s + wikidata_ender_test for s in wikidata_filenames]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c6dfc20-8e3a-4225-9259-d36a584dca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>rel_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>sent</th>\n",
       "      <th>sub</th>\n",
       "      <th>rel</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ont_1_movie_train_1</td>\n",
       "      <td>Urusei Yatsura 2: Beautiful Dreamer</td>\n",
       "      <td>director</td>\n",
       "      <td>Mamoru Oshii</td>\n",
       "      <td>Urusei Yatsura 2: Beautiful Dreamer (Japanese: , Hepburn: Urusei Yatsura 2 ByÅ«tifuru DorÄ«mÄ) is a 1984 Japanese anime fantasy comedy film, directed by Mamoru Oshii.</td>\n",
       "      <td>Q1582185</td>\n",
       "      <td>P57</td>\n",
       "      <td>Q285084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ont_1_movie_train_2</td>\n",
       "      <td>She and Her Cat</td>\n",
       "      <td>director</td>\n",
       "      <td>Makoto Shinkai</td>\n",
       "      <td>She and Her Cat (Japanese: , Hepburn: Kanojo to Kanojo no Neko), subtitled Their standing points, is a 1999 Japanese original video animation created and directed by Makoto Shinkai.</td>\n",
       "      <td>Q584204</td>\n",
       "      <td>P57</td>\n",
       "      <td>Q335080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ont_1_movie_train_3</td>\n",
       "      <td>Minimum Viable Product</td>\n",
       "      <td>director</td>\n",
       "      <td>Mike Judge</td>\n",
       "      <td>The episode was written by series creators John Altschuler, Dave Krinsky and Mike Judge and directed by Judge.</td>\n",
       "      <td>Q16746501</td>\n",
       "      <td>P57</td>\n",
       "      <td>Q434585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ont_1_movie_train_4</td>\n",
       "      <td>Evangelion: 3.0 You Can (Not) Redo</td>\n",
       "      <td>director</td>\n",
       "      <td>Hideaki Anno</td>\n",
       "      <td>(Q, Evangerion Shin GekijÅban: KyÅ«, \"Evangelion: The New Movie: Q\", where the \"Q\" stands for \"Quickening\") is a 2012 Japanese animated science fiction film written and chief directed by Hideaki Anno and the third of four films released in the Rebuild of Evangelion tetralogy, based on the original anime series Neon Genesis Evangelion.</td>\n",
       "      <td>Q182206</td>\n",
       "      <td>P57</td>\n",
       "      <td>Q23261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ont_1_movie_train_5</td>\n",
       "      <td>Evangelion: 2.0 You Can (Not) Advance</td>\n",
       "      <td>director</td>\n",
       "      <td>Hideaki Anno</td>\n",
       "      <td>Evangelion : 2.0 You Can ( Not ) Advance was produced and co-distributed by Hideaki Anno's Studio Khara in partnership with Gainax.</td>\n",
       "      <td>Q614200</td>\n",
       "      <td>P57</td>\n",
       "      <td>Q23261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                              sub_label rel_label  \\\n",
       "0  ont_1_movie_train_1    Urusei Yatsura 2: Beautiful Dreamer  director   \n",
       "1  ont_1_movie_train_2                        She and Her Cat  director   \n",
       "2  ont_1_movie_train_3                 Minimum Viable Product  director   \n",
       "3  ont_1_movie_train_4     Evangelion: 3.0 You Can (Not) Redo  director   \n",
       "4  ont_1_movie_train_5  Evangelion: 2.0 You Can (Not) Advance  director   \n",
       "\n",
       "        obj_label  \\\n",
       "0    Mamoru Oshii   \n",
       "1  Makoto Shinkai   \n",
       "2      Mike Judge   \n",
       "3    Hideaki Anno   \n",
       "4    Hideaki Anno   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                sent  \\\n",
       "0                                                                                                                                                                            Urusei Yatsura 2: Beautiful Dreamer (Japanese: , Hepburn: Urusei Yatsura 2 ByÅ«tifuru DorÄ«mÄ) is a 1984 Japanese anime fantasy comedy film, directed by Mamoru Oshii.   \n",
       "1                                                                                                                                                              She and Her Cat (Japanese: , Hepburn: Kanojo to Kanojo no Neko), subtitled Their standing points, is a 1999 Japanese original video animation created and directed by Makoto Shinkai.   \n",
       "2                                                                                                                                                                                                                                     The episode was written by series creators John Altschuler, Dave Krinsky and Mike Judge and directed by Judge.   \n",
       "3  (Q, Evangerion Shin GekijÅban: KyÅ«, \"Evangelion: The New Movie: Q\", where the \"Q\" stands for \"Quickening\") is a 2012 Japanese animated science fiction film written and chief directed by Hideaki Anno and the third of four films released in the Rebuild of Evangelion tetralogy, based on the original anime series Neon Genesis Evangelion.   \n",
       "4                                                                                                                                                                                                                Evangelion : 2.0 You Can ( Not ) Advance was produced and co-distributed by Hideaki Anno's Studio Khara in partnership with Gainax.   \n",
       "\n",
       "         sub  rel      obj  \n",
       "0   Q1582185  P57  Q285084  \n",
       "1    Q584204  P57  Q335080  \n",
       "2  Q16746501  P57  Q434585  \n",
       "3    Q182206  P57   Q23261  \n",
       "4    Q614200  P57   Q23261  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wikidata_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90001bb0-9135-49dc-a5ec-7ceeedd13160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sent</th>\n",
       "      <th>triples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ont_1_movie_test_1</td>\n",
       "      <td>Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.</td>\n",
       "      <td>[{'sub': 'Bleach : Hell Verse', 'rel': 'director', 'obj': 'Noriyuki Abe'}, {'sub': 'Bleach : Hell Verse', 'rel': 'publication date', 'obj': '01 January 2010'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ont_1_movie_test_2</td>\n",
       "      <td>Keyboard Cat's original form was a video originally made in 1984 by Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.</td>\n",
       "      <td>[{'sub': 'Keyboard Cat', 'rel': 'cast member', 'obj': 'Fatso the Cat'}, {'sub': 'Keyboard Cat', 'rel': 'director', 'obj': 'Charlie Schmidt'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ont_1_movie_test_3</td>\n",
       "      <td>The series was directed by Mitsuko Kase (episodes 1-7) and Takashi Imanishi (episodes 8-13).</td>\n",
       "      <td>[{'sub': 'Mobile Suit Gundam 0083 : Stardust Memory', 'rel': 'director', 'obj': 'Takashi Imanishi'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ont_1_movie_test_4</td>\n",
       "      <td>Spirited Away (Japanese: , Hepburn: Sen to Chihiro no Kamikakushi, \"Sen and Chihiros Spiriting Away\") is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu, Buena Vista Home Entertainment, Tohokushinsha Film and Mitsubishi, and distributed by Toho.</td>\n",
       "      <td>[{'sub': 'Spirited Away', 'rel': 'genre', 'obj': 'Fantasy film'}, {'sub': 'Spirited Away', 'rel': 'director', 'obj': 'Hayao Miyazaki'}, {'sub': 'Spirited Away', 'rel': 'publication date', 'obj': '20 July 2001'}, {'sub': 'Spirited Away', 'rel': 'production company', 'obj': 'Studio Ghibli'}, {'sub': 'Spirited Away', 'rel': 'screenwriter', 'obj': 'Hayao Miyazaki'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ont_1_movie_test_5</td>\n",
       "      <td>Looney Tunes: Back in Action is a 2003 American live-action/animated comedy film directed by Joe Dante and written by Larry Doyle.</td>\n",
       "      <td>[{'sub': 'Looney Tunes : Back in Action', 'rel': 'director', 'obj': 'Joe Dante'}, {'sub': 'Looney Tunes : Back in Action', 'rel': 'publication date', 'obj': '01 January 2003'}, {'sub': 'Looney Tunes : Back in Action', 'rel': 'publication date', 'obj': '04 December 2003'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  \\\n",
       "0  ont_1_movie_test_1   \n",
       "1  ont_1_movie_test_2   \n",
       "2  ont_1_movie_test_3   \n",
       "3  ont_1_movie_test_4   \n",
       "4  ont_1_movie_test_5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                 sent  \\\n",
       "0                                                                                                                                                                                                                                     Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.   \n",
       "1                                                                                                                                                                         Keyboard Cat's original form was a video originally made in 1984 by Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.   \n",
       "2                                                                                                                                                                                                                                                                        The series was directed by Mitsuko Kase (episodes 1-7) and Takashi Imanishi (episodes 8-13).   \n",
       "3  Spirited Away (Japanese: , Hepburn: Sen to Chihiro no Kamikakushi, \"Sen and Chihiros Spiriting Away\") is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu, Buena Vista Home Entertainment, Tohokushinsha Film and Mitsubishi, and distributed by Toho.   \n",
       "4                                                                                                                                                                                                                                  Looney Tunes: Back in Action is a 2003 American live-action/animated comedy film directed by Joe Dante and written by Larry Doyle.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                        triples  \n",
       "0                                                                                                                                                                                                               [{'sub': 'Bleach : Hell Verse', 'rel': 'director', 'obj': 'Noriyuki Abe'}, {'sub': 'Bleach : Hell Verse', 'rel': 'publication date', 'obj': '01 January 2010'}]  \n",
       "1                                                                                                                                                                                                                                 [{'sub': 'Keyboard Cat', 'rel': 'cast member', 'obj': 'Fatso the Cat'}, {'sub': 'Keyboard Cat', 'rel': 'director', 'obj': 'Charlie Schmidt'}]  \n",
       "2                                                                                                                                                                                                                                                                          [{'sub': 'Mobile Suit Gundam 0083 : Stardust Memory', 'rel': 'director', 'obj': 'Takashi Imanishi'}]  \n",
       "3  [{'sub': 'Spirited Away', 'rel': 'genre', 'obj': 'Fantasy film'}, {'sub': 'Spirited Away', 'rel': 'director', 'obj': 'Hayao Miyazaki'}, {'sub': 'Spirited Away', 'rel': 'publication date', 'obj': '20 July 2001'}, {'sub': 'Spirited Away', 'rel': 'production company', 'obj': 'Studio Ghibli'}, {'sub': 'Spirited Away', 'rel': 'screenwriter', 'obj': 'Hayao Miyazaki'}]  \n",
       "4                                                                                              [{'sub': 'Looney Tunes : Back in Action', 'rel': 'director', 'obj': 'Joe Dante'}, {'sub': 'Looney Tunes : Back in Action', 'rel': 'publication date', 'obj': '01 January 2003'}, {'sub': 'Looney Tunes : Back in Action', 'rel': 'publication date', 'obj': '04 December 2003'}]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wikidata_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f13c5-3642-44d2-96d6-5f1d23642c19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Amazon Product Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec732fc8-b9d5-42c7-9dac-5de3806bdf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associated word embeddings are fine-tuned or trained\n",
    "\n",
    "# record different prompts tested\n",
    "# missing data: category (different from main_cat of \"Luxury Beauty\"?\n",
    "\n",
    "# dirty data like\n",
    "# \"\\n    Product Dimensions: \\n    \": \"2.2 x 2.2 x 7 inches ; 8.8 ounces\",\n",
    "# \"Shipping Weight:\": \"14.4 ounces (\",\n",
    "\n",
    "# remove trailing ' \\(' in strings\n",
    "# escape characters like &#039; but also non-escaped characters like &\n",
    "# increase response length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aa9e048-5a80-4cca-bcca-c816200352a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_folder = './' # current working directory\n",
    "amzn_filenames = [\n",
    "'sample_data_only_beauty_category.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701be7ab-9b19-4660-b38e-927769ef8dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tech1</th>\n",
       "      <th>description</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>tech2</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>details</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>similar_item</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>imageURL</th>\n",
       "      <th>imageURLHighRes</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[After a long day of handling thorny situations, our new hand therapy pump is just the help you need. It contains shea butter as well as extracts of yarrow, clover and calendula to help soothe and condition work-roughened hands., By Crabtree &amp; Evelyn, The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden., We&amp;#039;ve formulated our Gardeners Hand Therapy with Myrrh Extract to help condition nails and cuticles as well as skin super hydrators macadamia seed oil and shea butter to help replenish lost moisture. Rich in herbal extracts like cooling cucumber and rosemary leaf  a favourite for antioxidants  to help protect hands against daily urban and environmental stresses while the hydrating power of Vitamin E, Hyaluronic Acid and Ceramides contribute to improve the skins natural moisture barrier with this garden-inspired treatment. Skin is left silky-soft and delicately scented., How to use:, Dab a pea-sized amount to palms and work over skin and nails. Combine with Gardeners Hand Wash and Hand Scrub to get silky skin in three herb-infused steps., Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract., We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day.]</td>\n",
       "      <td></td>\n",
       "      <td>Crabtree &amp;amp; Evelyn - Gardener's Ultra-Moisturising Hand Therapy Pump - 250g/8.8 OZ</td>\n",
       "      <td>[B00GHX7H0A, B00FRERO7G, B00R68QXCS, B000Z65AZE, B07GFHJRMX, B074KGBGL7, B00R68QXJG, B00025WYZC, B07H3W9BM5, B00KOBT82G, B072N2M1P6, B071G8FG2N, B00FASVFI8, B00GHXE4N8, B00EPG2QJI, B01MQ4MEFE, B01M8ML0SY, B074KHCPLH, B004XQWY4W, B00FASV6UU, B01M31HJBJ, B00KC8TU7O, B00B9TU5T2, B00K75EZ04, B000Q2Y0FI, B00FEGOCCM, B00EPFXFBW, B00H6SQY3Q, B00HZAOWUC, B07GFJF1DN, B001WBS68E, B074KJZCPH]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>4,324 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[B00FRERO7G, B00GHX7H0A, B07GFHJRMX, B00TJ3NBN2, B00KOBT82G, B00R68QXCS, B074KGBGL7, B075MH4Q9L, B07H3W9BM5, B07GFJF1DN, B00KC8TPVA, B07DB7KXFV, B07DCCRGZT, B00GHX58LK, B077GXQ2TH, B00GHX52MK, B01MQ4MEFE, B00GHXE4N8, B07FYFXBK8, B00FEGOCCM, B00FASVFI8, B074KFH9JN, B071G8FG2N, B074KGN1BT, B00GHX5HZC, B00B9TU5T2, B074KM26WX, B074KGQ65V, B01M8ML0SY, B076YKGPY5, B00EPG2QJI, B074KHCPLH, B075YMZVGF, B00K1C8V1W, B074KDPT26, B07CCNVW87, B074KGQ5LF, B00GHX8I6M, B07JMLGRKY, B07C92VLKM, B00KC8TU7O, B00025WYZC, B074KJZCPH, B074KHCPMV, B00GHXHPEI, B07K2WRDBS, B00FASV6UU, B001WBS68E, B074KMD9QM, B076YN8DDY, B074KHDYRX, B00GHXIBGE]</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '2.2 x 2.2 x 7 inches ; 8.8 ounces', 'Shipping Weight:': '14.4 ounces (', 'Domestic Shipping: ': 'Item can be shipped within U.S.', 'International Shipping: ': 'This item can be shipped to select countries outside of the U.S.', 'ASIN:': 'B00004U9V2', 'Item model number:': '4113'}</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>$30.00</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/41ClX6BRvZL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/510giIO5cFL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/414gBlQ6F9L._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/51jNGOh1f9L._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/31f8YZgUBhL._SX50_SY65_CR,0,0,50,65_.jpg]</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/41ClX6BRvZL.jpg, https://images-na.ssl-images-amazon.com/images/I/510giIO5cFL.jpg, https://images-na.ssl-images-amazon.com/images/I/414gBlQ6F9L.jpg, https://images-na.ssl-images-amazon.com/images/I/51jNGOh1f9L.jpg, https://images-na.ssl-images-amazon.com/images/I/31f8YZgUBhL.jpg]</td>\n",
       "      <td>After a long day of handling thorny situations, our new hand therapy pump is just the help you need. It contains shea butter as well as extracts of yarrow, clover and calendula to help soothe and condition work-roughened hands. By Crabtree &amp; Evelyn The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden. We&amp;#039;ve formulated our Gardeners Hand Therapy with Myrrh Extract to help condition nails and cuticles as well as skin super hydrators macadamia seed oil and shea butter to help replenish lost moisture. Rich in herbal extracts like cooling cucumber and rosemary leaf  a favourite for antioxidants  to help protect hands against daily urban and environmental stresses while the hydrating power of Vitamin E, Hyaluronic Acid and Ceramides contribute to improve the skins natural moisture barrier with this garden-inspired treatment. Skin is left silky-soft and delicately scented. How to use: Dab a pea-sized amount to palms and work over skin and nails. Combine with Gardeners Hand Wash and Hand Scrub to get silky skin in three herb-infused steps. Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract. We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[If you haven't experienced the pleasures of bathing in the Dead Sea, Bath Crystals are the next best thing. Rich in health-inducing minerals including magnesium, calcium, sodium, potassium and more, they soothe your body with relaxation, easing muscle tension and softening your skin. Immerse yourself in the waters of well-being.]</td>\n",
       "      <td></td>\n",
       "      <td>AHAVA Bath Salts</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1,633,549 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '3 x 3.5 x 6 inches ; 2.2 pounds', 'Shipping Weight:': '2.6 pounds', 'Domestic Shipping: ': 'Item can be shipped within U.S.', 'International Shipping: ': 'This item is not eligible for international shipping.', 'ASIN:': 'B0000531EN', 'Item model number:': '017N'}</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td>B0000531EN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>If you haven't experienced the pleasures of bathing in the Dead Sea, Bath Crystals are the next best thing. Rich in health-inducing minerals including magnesium, calcium, sodium, potassium and more, they soothe your body with relaxation, easing muscle tension and softening your skin. Immerse yourself in the waters of well-being.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[Rich, black mineral mud, harvested from the banks of the Dead Sea, is comprised of layer upon layer of sedimentary clay formed over thousands of years. Captured within is an extremely high concentration of minerals, scientifically proven to be essential in maintaining healthy skin. Ahava Black Mineral Mud works deep to clean, purify and restore the skin's natural moisture balance, leaving it smooth, radiant and revitalized., , ]</td>\n",
       "      <td></td>\n",
       "      <td>AHAVA Dead Sea Mineral Mud, 8.5 oz, Pack of 4</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1,806,710 in Beauty &amp;amp; Personal Care (</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '5.1 x 3 x 5.5 inches ; 2.48 pounds', 'Shipping Weight:': '2.6 pounds', 'Domestic Shipping: ': 'Item can be shipped within U.S.', 'International Shipping: ': 'This item is not eligible for international shipping.', 'ASIN:': 'B0000532JH', 'Item model number:': '018N'}</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td>B0000532JH</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/41O1luEZuHL._SX50_SY65_CR,0,0,50,65_.jpg]</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/41O1luEZuHL.jpg]</td>\n",
       "      <td>Rich, black mineral mud, harvested from the banks of the Dead Sea, is comprised of layer upon layer of sedimentary clay formed over thousands of years. Captured within is an extremely high concentration of minerals, scientifically proven to be essential in maintaining healthy skin. Ahava Black Mineral Mud works deep to clean, purify and restore the skin's natural moisture balance, leaving it smooth, radiant and revitalized.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[This liquid soap with convenient pump dispenser is formulated with conditioning extracts of sage, rosemary, alfalfa, carrot, and cucumber. It deodorizes the skin and leaves it refreshed with a clean, herbal scent., You've watched your favorite gardeners spend hours lovingly pampering their plants, doting all weekend on tulips or carrots or tomatoes, but when was the last time they doted on themselves? Crabtree &amp;amp; Evelyn comes to the rescue of gardeners' hands everywhere with their line of lavish skin-care products. Their hand soap is made from a vegetable-base blend and features sage, alfalfa, and cucumber extracts. It's packaged in a handy metal pump dispenser, and has been formulated to be gentle on a gardener's hands for pampering after a long day in the dirt. Combine this with other Crabtree &amp;amp; Evelyn accessories like Gardeners Hand Therapy or Skin Remedy for a fantastic gift set. Indulge your favorite gardeners (or yourself) with this well-deserved treat. &lt;i&gt;--Ariel Meadow Stallings&lt;/i&gt;, The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden., This cleansing, fragrant hand wash has the power to transport you away from the city and straight to the countryside thanks to its heady mix of herbal heavyweights. With clarifying cucumber, antioxidant-rich rosemary leaf and soothing aloe leaf juice, hands will be cleansed and revived with the freshest of scents. Like a restorative tonic, Gardeners Hand Soap is mild and gentle to leave you with petal-soft hands., How to use:, For thoroughly cleansed, silky soft hands, dab a pea-sized amount of soap onto skin and lather well under warm water. Rinse and pat dry. Combine the Hand Wash with our Exfoliating Hand Scrub and Moisturising Hand Therapy for the ultimate ritual., Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract., We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day., , ]</td>\n",
       "      <td></td>\n",
       "      <td>Crabtree &amp;amp; Evelyn Hand Soap, Gardeners, 10.1 fl. oz.</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[B00004U9V2, B00GHX7H0A, B00FRERO7G, B00R68QXCS, B00KOBT82G, B071G8FG2N, B07FYFXBK8, B00TJ3NBN2, B07H3W9BM5, B074KGBGL7, B00EPG2QJI, B07GFJF1DN, B00GHXE4N8, B07DCCRGZT, B07GFHJRMX, B07BNL4LY4, B07JMLGRKY, B07DB7KXFV, B00R68QXJG, B00GHX58LK, B075MH4Q9L, B075YMT1ZY, B00K1C6D3A, B00KC8TPVA, B00GHX52MK, B074KDPT26, B074KJZCPH, B07CCNVW87, B074KK461V, B074KHCPLH, B00TJ3TF8C, B07LFXPK3N, B004MJVVBC, B0771SDCTB, B07CKMW2QH, B06XV5XTPQ, B0798FVV6V]</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '2.6 x 2.6 x 6.7 inches ; 1.5 pounds', 'Shipping Weight:': '12 ounces (', 'ASIN:': 'B00005A77F', 'Item model number:': '27810'}</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>$15.99</td>\n",
       "      <td>B00005A77F</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/31BBeRbXZsL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/41Qwup7twjL._SX50_SY65_CR,0,0,50,65_.jpg]</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/31BBeRbXZsL.jpg, https://images-na.ssl-images-amazon.com/images/I/41Qwup7twjL.jpg]</td>\n",
       "      <td>This liquid soap with convenient pump dispenser is formulated with conditioning extracts of sage, rosemary, alfalfa, carrot, and cucumber. It deodorizes the skin and leaves it refreshed with a clean, herbal scent. You've watched your favorite gardeners spend hours lovingly pampering their plants, doting all weekend on tulips or carrots or tomatoes, but when was the last time they doted on themselves? Crabtree &amp;amp; Evelyn comes to the rescue of gardeners' hands everywhere with their line of lavish skin-care products. Their hand soap is made from a vegetable-base blend and features sage, alfalfa, and cucumber extracts. It's packaged in a handy metal pump dispenser, and has been formulated to be gentle on a gardener's hands for pampering after a long day in the dirt. Combine this with other Crabtree &amp;amp; Evelyn accessories like Gardeners Hand Therapy or Skin Remedy for a fantastic gift set. Indulge your favorite gardeners (or yourself) with this well-deserved treat. &lt;i&gt;--Ariel Meadow Stallings&lt;/i&gt; The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden. This cleansing, fragrant hand wash has the power to transport you away from the city and straight to the countryside thanks to its heady mix of herbal heavyweights. With clarifying cucumber, antioxidant-rich rosemary leaf and soothing aloe leaf juice, hands will be cleansed and revived with the freshest of scents. Like a restorative tonic, Gardeners Hand Soap is mild and gentle to leave you with petal-soft hands. How to use: For thoroughly cleansed, silky soft hands, dab a pea-sized amount of soap onto skin and lather well under warm water. Rinse and pat dry. Combine the Hand Wash with our Exfoliating Hand Scrub and Moisturising Hand Therapy for the ultimate ritual. Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract. We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[Remember why you love your favorite blanket? The soft, comforting feeling of wrapping it around your shoulders gives you the instant happiness of a hug. Your hands deserve the same love. With every application, soy extract blended with dried milk solids and whipped to perfection greets your hands with loving hydration. A favorite among nutrition experts, soy extract is the primary ingredient in our Soy Milk Hand Crme. The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Natural jojoba esters and other premium ingredients are added to allow the cream to go on smoothly, without that greasy feel. The final result is a distinctive cream that you will love from the first time it's applied., Welcome to the world of Archipelago Botanicals - where warm candlelight, exquisite fragrance, and soothing products make a house a home., This beautician favorite collection features dried milk solids and natural proteins to gently nurture and soothe the skin, leaving it naturally soft and supple. Available in soy and oat proteins or in combination blends of the two., &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/e6bd20a0-5d75-4f4d-b4cb-621bfdf8d387._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt;, &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/d4c325ad-9d90-42f8-89a9-769fd1b3eda1._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt;, &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/cf60e661-f2c6-4e70-885b-e9e2009e8039._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt;, Soy protein makes the perfect additive for the skin! The amino acids and lipids found in this high-powered bean allow for rapid cell rehydration and regeneration. Our soy lotion is blended with dried milk solids to keep skin looking and feeling soft and supple. Natural jojoba esters and other premium ingredients are added to allow the lotion to go on smoothly, without that greasy feel. The final result is a distinctive lotion that youll appreciate the very first time that it touches your skin., Gentle Oat Proteins are the perfect solution for your dry skin! Our Oat Lotion is blended with dried Milk Solids to keep skin looking and feeling soft and supple. Natural Jojoba Esters and other premium ingredients, are added to allow the lotion to go on smoothly without leaving a greasy feel. The final result is a distinctive lotion that you will love the first time it's applied., The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Our hand cream is blended with dried milk solids to keep hands looking and feeling soft and supple. Our irresistibly scented hand treatment is highly recommended as part of your daily skin care routine for beautiful and soft hands., &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/4b4f2e9c-091d-4ca6-928e-cee8edf88107._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt;, &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/8b5e5e72-92c4-4678-97a4-94b9b4dee0c8._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt;, &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/905dc348-f67c-484b-80b9-fc0269e8df71._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt;, Our Oat Milk Hand Crme is perfect for dry or chapped hands! Gentle Oat Proteins are mixed with Aloe, resulting in one of the best moisturizing formulations on the market., Our Milk Hand Wash is the perfect soap to keep your hands looking healthy and clean. Dried Milk Solids and Natural Soy, Oat, and Rice proteins are combine to create this distinctive hand wash that you will love from the first time you use it. Apply liberally and work into a robust lather and rinse. Gentle enough for everyday use., Begin your daily beauty routine with a gentle, foaming cleanser from one of Archipelago Botanicals aromatherapy bath and body collections. This moisturizing body wash is highly recommended for dry skin. Also available in a larger, 33 oz bottle., , ]</td>\n",
       "      <td></td>\n",
       "      <td>Soy Milk Hand Crme</td>\n",
       "      <td>[B000NZT6KM, B001BY229Q, B008J724QY, B0009YGKJ2, B001JB55SQ, B000M3OR7C, B00J0A3ZCQ, B00SKBJ4L2, B00J0A3SMS, B008J720A4, B00J0A448K, B00NT183UQ, B01FCKKU3E, B01DSM1R6M, B001IJQR68, B01KZ20SZE, B002JU6IQO, B00J0A3JW2, B008J72D2Y, B003B3YBK8, B008J721L2, B0002PFDYQ, B00J9PYCJW, 0393326349, B001AH8CL6, B07HS8P7S4, B001IJOYJA, B00FJGGJXW, B000066SYB, B07BKNG24Z, B00GNW1MB0, B000YB6PQS, B00YWRKHPK]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>42,464 in Beauty &amp;amp; Personal Care (</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '7.2 x 2.2 x 7.2 inches ; 4 ounces', 'Shipping Weight:': '7.2 ounces (', 'Domestic Shipping: ': 'Currently, item can be shipped only within the U.S. and to APO/FPO addresses. For APO/FPO shipments, please check with the manufacturer regarding warranty and support issues.', 'International Shipping: ': 'This item can be shipped to select countries outside of the U.S.', 'ASIN:': 'B00005NDTD', 'Item model number:': '27418'}</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>$18.00</td>\n",
       "      <td>B00005NDTD</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/31agMAVCHtL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/41xps4ua3ZL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/413s80q%2BjRL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/31GmuRIx5kL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/31C6Z%2B9RuLL._SX50_SY65_CR,0,0,50,65_.jpg]</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/images/I/31agMAVCHtL.jpg, https://images-na.ssl-images-amazon.com/images/I/41xps4ua3ZL.jpg, https://images-na.ssl-images-amazon.com/images/I/413s80q%2BjRL.jpg, https://images-na.ssl-images-amazon.com/images/I/31GmuRIx5kL.jpg, https://images-na.ssl-images-amazon.com/images/I/31C6Z%2B9RuLL.jpg]</td>\n",
       "      <td>Remember why you love your favorite blanket? The soft, comforting feeling of wrapping it around your shoulders gives you the instant happiness of a hug. Your hands deserve the same love. With every application, soy extract blended with dried milk solids and whipped to perfection greets your hands with loving hydration. A favorite among nutrition experts, soy extract is the primary ingredient in our Soy Milk Hand Crme. The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Natural jojoba esters and other premium ingredients are added to allow the cream to go on smoothly, without that greasy feel. The final result is a distinctive cream that you will love from the first time it's applied. Welcome to the world of Archipelago Botanicals - where warm candlelight, exquisite fragrance, and soothing products make a house a home. This beautician favorite collection features dried milk solids and natural proteins to gently nurture and soothe the skin, leaving it naturally soft and supple. Available in soy and oat proteins or in combination blends of the two. &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/e6bd20a0-5d75-4f4d-b4cb-621bfdf8d387._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt; &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/d4c325ad-9d90-42f8-89a9-769fd1b3eda1._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt; &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/cf60e661-f2c6-4e70-885b-e9e2009e8039._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt; Soy protein makes the perfect additive for the skin! The amino acids and lipids found in this high-powered bean allow for rapid cell rehydration and regeneration. Our soy lotion is blended with dried milk solids to keep skin looking and feeling soft and supple. Natural jojoba esters and other premium ingredients are added to allow the lotion to go on smoothly, without that greasy feel. The final result is a distinctive lotion that youll appreciate the very first time that it touches your skin. Gentle Oat Proteins are the perfect solution for your dry skin! Our Oat Lotion is blended with dried Milk Solids to keep skin looking and feeling soft and supple. Natural Jojoba Esters and other premium ingredients, are added to allow the lotion to go on smoothly without leaving a greasy feel. The final result is a distinctive lotion that you will love the first time it's applied. The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Our hand cream is blended with dried milk solids to keep hands looking and feeling soft and supple. Our irresistibly scented hand treatment is highly recommended as part of your daily skin care routine for beautiful and soft hands. &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/4b4f2e9c-091d-4ca6-928e-cee8edf88107._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt; &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/8b5e5e72-92c4-4678-97a4-94b9b4dee0c8._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt; &lt;img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/905dc348-f67c-484b-80b9-fc0269e8df71._SL300__.jpg\" class=\"a-spacing-mini\" /&gt;\\n    \\n\\n\\n                            &lt;br /&gt; Our Oat Milk Hand Crme is perfect for dry or chapped hands! Gentle Oat Proteins are mixed with Aloe, resulting in one of the best moisturizing formulations on the market. Our Milk Hand Wash is the perfect soap to keep your hands looking healthy and clean. Dried Milk Solids and Natural Soy, Oat, and Rice proteins are combine to create this distinctive hand wash that you will love from the first time you use it. Apply liberally and work into a robust lather and rinse. Gentle enough for everyday use. Begin your daily beauty routine with a gentle, foaming cleanser from one of Archipelago Botanicals aromatherapy bath and body collections. This moisturizing body wash is highly recommended for dry skin. Also available in a larger, 33 oz bottle.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category tech1  \\\n",
       "0       []         \n",
       "1       []         \n",
       "2       []         \n",
       "3       []         \n",
       "4       []         \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              description  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [After a long day of handling thorny situations, our new hand therapy pump is just the help you need. It contains shea butter as well as extracts of yarrow, clover and calendula to help soothe and condition work-roughened hands., By Crabtree & Evelyn, The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden., We&#039;ve formulated our Gardeners Hand Therapy with Myrrh Extract to help condition nails and cuticles as well as skin super hydrators macadamia seed oil and shea butter to help replenish lost moisture. Rich in herbal extracts like cooling cucumber and rosemary leaf  a favourite for antioxidants  to help protect hands against daily urban and environmental stresses while the hydrating power of Vitamin E, Hyaluronic Acid and Ceramides contribute to improve the skins natural moisture barrier with this garden-inspired treatment. Skin is left silky-soft and delicately scented., How to use:, Dab a pea-sized amount to palms and work over skin and nails. Combine with Gardeners Hand Wash and Hand Scrub to get silky skin in three herb-infused steps., Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract., We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day.]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [If you haven't experienced the pleasures of bathing in the Dead Sea, Bath Crystals are the next best thing. Rich in health-inducing minerals including magnesium, calcium, sodium, potassium and more, they soothe your body with relaxation, easing muscle tension and softening your skin. Immerse yourself in the waters of well-being.]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [Rich, black mineral mud, harvested from the banks of the Dead Sea, is comprised of layer upon layer of sedimentary clay formed over thousands of years. Captured within is an extremely high concentration of minerals, scientifically proven to be essential in maintaining healthy skin. Ahava Black Mineral Mud works deep to clean, purify and restore the skin's natural moisture balance, leaving it smooth, radiant and revitalized., , ]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [This liquid soap with convenient pump dispenser is formulated with conditioning extracts of sage, rosemary, alfalfa, carrot, and cucumber. It deodorizes the skin and leaves it refreshed with a clean, herbal scent., You've watched your favorite gardeners spend hours lovingly pampering their plants, doting all weekend on tulips or carrots or tomatoes, but when was the last time they doted on themselves? Crabtree &amp; Evelyn comes to the rescue of gardeners' hands everywhere with their line of lavish skin-care products. Their hand soap is made from a vegetable-base blend and features sage, alfalfa, and cucumber extracts. It's packaged in a handy metal pump dispenser, and has been formulated to be gentle on a gardener's hands for pampering after a long day in the dirt. Combine this with other Crabtree &amp; Evelyn accessories like Gardeners Hand Therapy or Skin Remedy for a fantastic gift set. Indulge your favorite gardeners (or yourself) with this well-deserved treat. <i>--Ariel Meadow Stallings</i>, The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden., This cleansing, fragrant hand wash has the power to transport you away from the city and straight to the countryside thanks to its heady mix of herbal heavyweights. With clarifying cucumber, antioxidant-rich rosemary leaf and soothing aloe leaf juice, hands will be cleansed and revived with the freshest of scents. Like a restorative tonic, Gardeners Hand Soap is mild and gentle to leave you with petal-soft hands., How to use:, For thoroughly cleansed, silky soft hands, dab a pea-sized amount of soap onto skin and lather well under warm water. Rinse and pat dry. Combine the Hand Wash with our Exfoliating Hand Scrub and Moisturising Hand Therapy for the ultimate ritual., Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract., We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day., , ]   \n",
       "4  [Remember why you love your favorite blanket? The soft, comforting feeling of wrapping it around your shoulders gives you the instant happiness of a hug. Your hands deserve the same love. With every application, soy extract blended with dried milk solids and whipped to perfection greets your hands with loving hydration. A favorite among nutrition experts, soy extract is the primary ingredient in our Soy Milk Hand Crme. The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Natural jojoba esters and other premium ingredients are added to allow the cream to go on smoothly, without that greasy feel. The final result is a distinctive cream that you will love from the first time it's applied., Welcome to the world of Archipelago Botanicals - where warm candlelight, exquisite fragrance, and soothing products make a house a home., This beautician favorite collection features dried milk solids and natural proteins to gently nurture and soothe the skin, leaving it naturally soft and supple. Available in soy and oat proteins or in combination blends of the two., <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/e6bd20a0-5d75-4f4d-b4cb-621bfdf8d387._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br />, <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/d4c325ad-9d90-42f8-89a9-769fd1b3eda1._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br />, <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/cf60e661-f2c6-4e70-885b-e9e2009e8039._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br />, Soy protein makes the perfect additive for the skin! The amino acids and lipids found in this high-powered bean allow for rapid cell rehydration and regeneration. Our soy lotion is blended with dried milk solids to keep skin looking and feeling soft and supple. Natural jojoba esters and other premium ingredients are added to allow the lotion to go on smoothly, without that greasy feel. The final result is a distinctive lotion that youll appreciate the very first time that it touches your skin., Gentle Oat Proteins are the perfect solution for your dry skin! Our Oat Lotion is blended with dried Milk Solids to keep skin looking and feeling soft and supple. Natural Jojoba Esters and other premium ingredients, are added to allow the lotion to go on smoothly without leaving a greasy feel. The final result is a distinctive lotion that you will love the first time it's applied., The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Our hand cream is blended with dried milk solids to keep hands looking and feeling soft and supple. Our irresistibly scented hand treatment is highly recommended as part of your daily skin care routine for beautiful and soft hands., <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/4b4f2e9c-091d-4ca6-928e-cee8edf88107._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br />, <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/8b5e5e72-92c4-4678-97a4-94b9b4dee0c8._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br />, <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/905dc348-f67c-484b-80b9-fc0269e8df71._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br />, Our Oat Milk Hand Crme is perfect for dry or chapped hands! Gentle Oat Proteins are mixed with Aloe, resulting in one of the best moisturizing formulations on the market., Our Milk Hand Wash is the perfect soap to keep your hands looking healthy and clean. Dried Milk Solids and Natural Soy, Oat, and Rice proteins are combine to create this distinctive hand wash that you will love from the first time you use it. Apply liberally and work into a robust lather and rinse. Gentle enough for everyday use., Begin your daily beauty routine with a gentle, foaming cleanser from one of Archipelago Botanicals aromatherapy bath and body collections. This moisturizing body wash is highly recommended for dry skin. Also available in a larger, 33 oz bottle., , ]   \n",
       "\n",
       "  fit  \\\n",
       "0       \n",
       "1       \n",
       "2       \n",
       "3       \n",
       "4       \n",
       "\n",
       "                                                                                   title  \\\n",
       "0  Crabtree &amp; Evelyn - Gardener's Ultra-Moisturising Hand Therapy Pump - 250g/8.8 OZ   \n",
       "1                                                                       AHAVA Bath Salts   \n",
       "2                                          AHAVA Dead Sea Mineral Mud, 8.5 oz, Pack of 4   \n",
       "3                               Crabtree &amp; Evelyn Hand Soap, Gardeners, 10.1 fl. oz.   \n",
       "4                                                                     Soy Milk Hand Crme   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                       also_buy  \\\n",
       "0              [B00GHX7H0A, B00FRERO7G, B00R68QXCS, B000Z65AZE, B07GFHJRMX, B074KGBGL7, B00R68QXJG, B00025WYZC, B07H3W9BM5, B00KOBT82G, B072N2M1P6, B071G8FG2N, B00FASVFI8, B00GHXE4N8, B00EPG2QJI, B01MQ4MEFE, B01M8ML0SY, B074KHCPLH, B004XQWY4W, B00FASV6UU, B01M31HJBJ, B00KC8TU7O, B00B9TU5T2, B00K75EZ04, B000Q2Y0FI, B00FEGOCCM, B00EPFXFBW, B00H6SQY3Q, B00HZAOWUC, B07GFJF1DN, B001WBS68E, B074KJZCPH]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "4  [B000NZT6KM, B001BY229Q, B008J724QY, B0009YGKJ2, B001JB55SQ, B000M3OR7C, B00J0A3ZCQ, B00SKBJ4L2, B00J0A3SMS, B008J720A4, B00J0A448K, B00NT183UQ, B01FCKKU3E, B01DSM1R6M, B001IJQR68, B01KZ20SZE, B002JU6IQO, B00J0A3JW2, B008J72D2Y, B003B3YBK8, B008J721L2, B0002PFDYQ, B00J9PYCJW, 0393326349, B001AH8CL6, B07HS8P7S4, B001IJOYJA, B00FJGGJXW, B000066SYB, B07BKNG24Z, B00GNW1MB0, B000YB6PQS, B00YWRKHPK]   \n",
       "\n",
       "  tech2 brand feature                                       rank  \\\n",
       "0                  []          4,324 in Beauty & Personal Care (   \n",
       "1                  []      1,633,549 in Beauty & Personal Care (   \n",
       "2                  []  1,806,710 in Beauty &amp; Personal Care (   \n",
       "3                  []                                         []   \n",
       "4                  []     42,464 in Beauty &amp; Personal Care (   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          also_view  \\\n",
       "0  [B00FRERO7G, B00GHX7H0A, B07GFHJRMX, B00TJ3NBN2, B00KOBT82G, B00R68QXCS, B074KGBGL7, B075MH4Q9L, B07H3W9BM5, B07GFJF1DN, B00KC8TPVA, B07DB7KXFV, B07DCCRGZT, B00GHX58LK, B077GXQ2TH, B00GHX52MK, B01MQ4MEFE, B00GHXE4N8, B07FYFXBK8, B00FEGOCCM, B00FASVFI8, B074KFH9JN, B071G8FG2N, B074KGN1BT, B00GHX5HZC, B00B9TU5T2, B074KM26WX, B074KGQ65V, B01M8ML0SY, B076YKGPY5, B00EPG2QJI, B074KHCPLH, B075YMZVGF, B00K1C8V1W, B074KDPT26, B07CCNVW87, B074KGQ5LF, B00GHX8I6M, B07JMLGRKY, B07C92VLKM, B00KC8TU7O, B00025WYZC, B074KJZCPH, B074KHCPMV, B00GHXHPEI, B07K2WRDBS, B00FASV6UU, B001WBS68E, B074KMD9QM, B076YN8DDY, B074KHDYRX, B00GHXIBGE]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "3                                                                                                                                                                                      [B00004U9V2, B00GHX7H0A, B00FRERO7G, B00R68QXCS, B00KOBT82G, B071G8FG2N, B07FYFXBK8, B00TJ3NBN2, B07H3W9BM5, B074KGBGL7, B00EPG2QJI, B07GFJF1DN, B00GHXE4N8, B07DCCRGZT, B07GFHJRMX, B07BNL4LY4, B07JMLGRKY, B07DB7KXFV, B00R68QXJG, B00GHX58LK, B075MH4Q9L, B075YMT1ZY, B00K1C6D3A, B00KC8TPVA, B00GHX52MK, B074KDPT26, B074KJZCPH, B07CCNVW87, B074KK461V, B074KHCPLH, B00TJ3TF8C, B07LFXPK3N, B004MJVVBC, B0771SDCTB, B07CKMW2QH, B06XV5XTPQ, B0798FVV6V]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                      details  \\\n",
       "0                                                                                                                                                 {'\n",
       "    Product Dimensions: \n",
       "    ': '2.2 x 2.2 x 7 inches ; 8.8 ounces', 'Shipping Weight:': '14.4 ounces (', 'Domestic Shipping: ': 'Item can be shipped within U.S.', 'International Shipping: ': 'This item can be shipped to select countries outside of the U.S.', 'ASIN:': 'B00004U9V2', 'Item model number:': '4113'}   \n",
       "1                                                                                                                                                                 {'\n",
       "    Product Dimensions: \n",
       "    ': '3 x 3.5 x 6 inches ; 2.2 pounds', 'Shipping Weight:': '2.6 pounds', 'Domestic Shipping: ': 'Item can be shipped within U.S.', 'International Shipping: ': 'This item is not eligible for international shipping.', 'ASIN:': 'B0000531EN', 'Item model number:': '017N'}   \n",
       "2                                                                                                                                                              {'\n",
       "    Product Dimensions: \n",
       "    ': '5.1 x 3 x 5.5 inches ; 2.48 pounds', 'Shipping Weight:': '2.6 pounds', 'Domestic Shipping: ': 'Item can be shipped within U.S.', 'International Shipping: ': 'This item is not eligible for international shipping.', 'ASIN:': 'B0000532JH', 'Item model number:': '018N'}   \n",
       "3                                                                                                                                                                                                                                                                                                          {'\n",
       "    Product Dimensions: \n",
       "    ': '2.6 x 2.6 x 6.7 inches ; 1.5 pounds', 'Shipping Weight:': '12 ounces (', 'ASIN:': 'B00005A77F', 'Item model number:': '27810'}   \n",
       "4  {'\n",
       "    Product Dimensions: \n",
       "    ': '7.2 x 2.2 x 7.2 inches ; 4 ounces', 'Shipping Weight:': '7.2 ounces (', 'Domestic Shipping: ': 'Currently, item can be shipped only within the U.S. and to APO/FPO addresses. For APO/FPO shipments, please check with the manufacturer regarding warranty and support issues.', 'International Shipping: ': 'This item can be shipped to select countries outside of the U.S.', 'ASIN:': 'B00005NDTD', 'Item model number:': '27418'}   \n",
       "\n",
       "        main_cat similar_item date   price        asin  \\\n",
       "0  Luxury Beauty               NaT  $30.00  B00004U9V2   \n",
       "1  Luxury Beauty               NaT          B0000531EN   \n",
       "2  Luxury Beauty               NaT          B0000532JH   \n",
       "3  Luxury Beauty               NaT  $15.99  B00005A77F   \n",
       "4  Luxury Beauty               NaT  $18.00  B00005NDTD   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                      imageURL  \\\n",
       "0      [https://images-na.ssl-images-amazon.com/images/I/41ClX6BRvZL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/510giIO5cFL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/414gBlQ6F9L._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/51jNGOh1f9L._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/31f8YZgUBhL._SX50_SY65_CR,0,0,50,65_.jpg]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                           []   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                  [https://images-na.ssl-images-amazon.com/images/I/41O1luEZuHL._SX50_SY65_CR,0,0,50,65_.jpg]   \n",
       "3                                                                                                                                                                                                                                                                                       [https://images-na.ssl-images-amazon.com/images/I/31BBeRbXZsL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/41Qwup7twjL._SX50_SY65_CR,0,0,50,65_.jpg]   \n",
       "4  [https://images-na.ssl-images-amazon.com/images/I/31agMAVCHtL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/41xps4ua3ZL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/413s80q%2BjRL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/31GmuRIx5kL._SX50_SY65_CR,0,0,50,65_.jpg, https://images-na.ssl-images-amazon.com/images/I/31C6Z%2B9RuLL._SX50_SY65_CR,0,0,50,65_.jpg]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                  imageURLHighRes  \\\n",
       "0      [https://images-na.ssl-images-amazon.com/images/I/41ClX6BRvZL.jpg, https://images-na.ssl-images-amazon.com/images/I/510giIO5cFL.jpg, https://images-na.ssl-images-amazon.com/images/I/414gBlQ6F9L.jpg, https://images-na.ssl-images-amazon.com/images/I/51jNGOh1f9L.jpg, https://images-na.ssl-images-amazon.com/images/I/31f8YZgUBhL.jpg]   \n",
       "1                                                                                                                                                                                                                                                                                                                                              []   \n",
       "2                                                                                                                                                                                                                                                                              [https://images-na.ssl-images-amazon.com/images/I/41O1luEZuHL.jpg]   \n",
       "3                                                                                                                                                                                                            [https://images-na.ssl-images-amazon.com/images/I/31BBeRbXZsL.jpg, https://images-na.ssl-images-amazon.com/images/I/41Qwup7twjL.jpg]   \n",
       "4  [https://images-na.ssl-images-amazon.com/images/I/31agMAVCHtL.jpg, https://images-na.ssl-images-amazon.com/images/I/41xps4ua3ZL.jpg, https://images-na.ssl-images-amazon.com/images/I/413s80q%2BjRL.jpg, https://images-na.ssl-images-amazon.com/images/I/31GmuRIx5kL.jpg, https://images-na.ssl-images-amazon.com/images/I/31C6Z%2B9RuLL.jpg]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   sent  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               After a long day of handling thorny situations, our new hand therapy pump is just the help you need. It contains shea butter as well as extracts of yarrow, clover and calendula to help soothe and condition work-roughened hands. By Crabtree & Evelyn The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden. We&#039;ve formulated our Gardeners Hand Therapy with Myrrh Extract to help condition nails and cuticles as well as skin super hydrators macadamia seed oil and shea butter to help replenish lost moisture. Rich in herbal extracts like cooling cucumber and rosemary leaf  a favourite for antioxidants  to help protect hands against daily urban and environmental stresses while the hydrating power of Vitamin E, Hyaluronic Acid and Ceramides contribute to improve the skins natural moisture barrier with this garden-inspired treatment. Skin is left silky-soft and delicately scented. How to use: Dab a pea-sized amount to palms and work over skin and nails. Combine with Gardeners Hand Wash and Hand Scrub to get silky skin in three herb-infused steps. Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract. We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            If you haven't experienced the pleasures of bathing in the Dead Sea, Bath Crystals are the next best thing. Rich in health-inducing minerals including magnesium, calcium, sodium, potassium and more, they soothe your body with relaxation, easing muscle tension and softening your skin. Immerse yourself in the waters of well-being.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Rich, black mineral mud, harvested from the banks of the Dead Sea, is comprised of layer upon layer of sedimentary clay formed over thousands of years. Captured within is an extremely high concentration of minerals, scientifically proven to be essential in maintaining healthy skin. Ahava Black Mineral Mud works deep to clean, purify and restore the skin's natural moisture balance, leaving it smooth, radiant and revitalized.    \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             This liquid soap with convenient pump dispenser is formulated with conditioning extracts of sage, rosemary, alfalfa, carrot, and cucumber. It deodorizes the skin and leaves it refreshed with a clean, herbal scent. You've watched your favorite gardeners spend hours lovingly pampering their plants, doting all weekend on tulips or carrots or tomatoes, but when was the last time they doted on themselves? Crabtree &amp; Evelyn comes to the rescue of gardeners' hands everywhere with their line of lavish skin-care products. Their hand soap is made from a vegetable-base blend and features sage, alfalfa, and cucumber extracts. It's packaged in a handy metal pump dispenser, and has been formulated to be gentle on a gardener's hands for pampering after a long day in the dirt. Combine this with other Crabtree &amp; Evelyn accessories like Gardeners Hand Therapy or Skin Remedy for a fantastic gift set. Indulge your favorite gardeners (or yourself) with this well-deserved treat. <i>--Ariel Meadow Stallings</i> The aromatic benefits of herbs are varied and far-reaching, so we combined a whole bunch of them into one restoratively fragrant line-up straight from the garden. This cleansing, fragrant hand wash has the power to transport you away from the city and straight to the countryside thanks to its heady mix of herbal heavyweights. With clarifying cucumber, antioxidant-rich rosemary leaf and soothing aloe leaf juice, hands will be cleansed and revived with the freshest of scents. Like a restorative tonic, Gardeners Hand Soap is mild and gentle to leave you with petal-soft hands. How to use: For thoroughly cleansed, silky soft hands, dab a pea-sized amount of soap onto skin and lather well under warm water. Rinse and pat dry. Combine the Hand Wash with our Exfoliating Hand Scrub and Moisturising Hand Therapy for the ultimate ritual. Originally created to appeal to a horticulturists wealth of knowledge about the healing power of herbs, this botanical range is formulated with cleansing cucumber extract, purifying rosemary extract, oak moss and refreshing sage extract. We search the world for natural ingredients and fragrance journeys that enable our customers to live a life cultivated. Inspired by the Crabapple Tree, the original species from which all cultivated apple trees have derived, and John Evelyn, the 17th century renaissance Englishman whose motto Explore Everything. Keep The Best has provided inspiration from our founding to this day.    \n",
       "4  Remember why you love your favorite blanket? The soft, comforting feeling of wrapping it around your shoulders gives you the instant happiness of a hug. Your hands deserve the same love. With every application, soy extract blended with dried milk solids and whipped to perfection greets your hands with loving hydration. A favorite among nutrition experts, soy extract is the primary ingredient in our Soy Milk Hand Crme. The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Natural jojoba esters and other premium ingredients are added to allow the cream to go on smoothly, without that greasy feel. The final result is a distinctive cream that you will love from the first time it's applied. Welcome to the world of Archipelago Botanicals - where warm candlelight, exquisite fragrance, and soothing products make a house a home. This beautician favorite collection features dried milk solids and natural proteins to gently nurture and soothe the skin, leaving it naturally soft and supple. Available in soy and oat proteins or in combination blends of the two. <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/e6bd20a0-5d75-4f4d-b4cb-621bfdf8d387._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br /> <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/d4c325ad-9d90-42f8-89a9-769fd1b3eda1._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br /> <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/cf60e661-f2c6-4e70-885b-e9e2009e8039._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br /> Soy protein makes the perfect additive for the skin! The amino acids and lipids found in this high-powered bean allow for rapid cell rehydration and regeneration. Our soy lotion is blended with dried milk solids to keep skin looking and feeling soft and supple. Natural jojoba esters and other premium ingredients are added to allow the lotion to go on smoothly, without that greasy feel. The final result is a distinctive lotion that youll appreciate the very first time that it touches your skin. Gentle Oat Proteins are the perfect solution for your dry skin! Our Oat Lotion is blended with dried Milk Solids to keep skin looking and feeling soft and supple. Natural Jojoba Esters and other premium ingredients, are added to allow the lotion to go on smoothly without leaving a greasy feel. The final result is a distinctive lotion that you will love the first time it's applied. The proteins, amino acids and lipids in this high-powered bean allow for rapid hydration and skin regeneration. Our hand cream is blended with dried milk solids to keep hands looking and feeling soft and supple. Our irresistibly scented hand treatment is highly recommended as part of your daily skin care routine for beautiful and soft hands. <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/4b4f2e9c-091d-4ca6-928e-cee8edf88107._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br /> <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/8b5e5e72-92c4-4678-97a4-94b9b4dee0c8._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br /> <img alt=\"\" src=\"https://m.media-amazon.com/images/S/aplus-media/vc/905dc348-f67c-484b-80b9-fc0269e8df71._SL300__.jpg\" class=\"a-spacing-mini\" />\\n    \\n\\n\\n                            <br /> Our Oat Milk Hand Crme is perfect for dry or chapped hands! Gentle Oat Proteins are mixed with Aloe, resulting in one of the best moisturizing formulations on the market. Our Milk Hand Wash is the perfect soap to keep your hands looking healthy and clean. Dried Milk Solids and Natural Soy, Oat, and Rice proteins are combine to create this distinctive hand wash that you will love from the first time you use it. Apply liberally and work into a robust lather and rinse. Gentle enough for everyday use. Begin your daily beauty routine with a gentle, foaming cleanser from one of Archipelago Botanicals aromatherapy bath and body collections. This moisturizing body wash is highly recommended for dry skin. Also available in a larger, 33 oz bottle.    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amzn_data = load_dataframe_from_jsonl(\n",
    "    amzn_folder\n",
    "    ,[s for s in amzn_filenames]\n",
    ")\n",
    "# shape df_amzn in the format expected by our CustomDataset\n",
    "# amzn_data.rename(columns={\"description\": \"sent\"}, inplace=True) -- A list of strings\n",
    "\n",
    "# change description column from a list of strings as a single string\n",
    "amzn_data['sent'] = amzn_data['description'].apply(lambda x: ' '.join(map(str, x)))\n",
    "amzn_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35bd6c5a-6502-4884-a32a-1792014f3648",
   "metadata": {},
   "source": [
    "-- Testing\n",
    "\n",
    "from CustomDataset import CustomDataset\n",
    "amzn_dataset = CustomDataset(tokenizer=tokenizer, dataset=amzn_data, type_path='test')\n",
    "for i in range(len(amzn_dataset)):\n",
    "    _ = amzn_dataset[i]\n",
    "data = amzn_dataset[0]\n",
    "\n",
    "print(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\n",
    "print(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))\n",
    "*/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962a0e7-ecb6-4dfd-8d3e-347f03f6dd3e",
   "metadata": {},
   "source": [
    "# Flan-T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce8b4f-4bfe-4416-a881-6c98cea6bfb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Toy Example with Base Flan-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fe161a4-1837-49b3-9f52-acf78d445bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "def run_toy_example():\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    \n",
    "    # https://github.com/huggingface/transformers/issues/7002\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    \n",
    "    #quantization_config = BitsAndBytesConfig(\n",
    "    #    load_in_4bit=True,\n",
    "    #    bnb_4bit_use_double_quant=False\n",
    "    #)\n",
    "    \n",
    "    #tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    #model = AutoModelForSeq2SeqLM.from_pretrained(model_name, quantization_config=quantization_config)\n",
    "    #input_ids = tokenizer(text, return_tensors=\"pt\", padding=True).to(0)\n",
    "    \n",
    "    index = 200\n",
    "    prompt = df_wikidata_train.iloc[[index]]['sent'].astype('string').to_string()\n",
    "    print(prompt)\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True).input_ids\n",
    "    \n",
    "    #outputs = model.generate(input_ids)\n",
    "    #out = model.generate(**input_ids, max_new_tokens=100, do_sample=False)\n",
    "    outputs = model.generate(input_ids, max_new_tokens=100, do_sample=False)\n",
    "    \n",
    "    #print(tokenizer.decode(outputs[0]))\n",
    "    a = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)\n",
    "    print(a)\n",
    "\n",
    "# run_toy_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200188b5-5a46-4428-9339-def03c97e113",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## T5FineTuner Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbc13ca8-53c3-4b07-8252-0610e8b4e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparam):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.num_dataloader_workers = 6 # 6 CPU cores; original code used 2\n",
    "        self.hparam = hparam\n",
    "\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            hparam.model_name_or_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            hparam.model_name_or_path\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # manual optimization\n",
    "        self.automatic_optimization = False\n",
    "    \n",
    "    def is_logger(self):\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "    ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Manual Optimization\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.log(\"batch_idx\", batch_idx)\n",
    "        loss = self._step(batch) # compute loss\n",
    "\n",
    "        self.manual_backward(loss) # manual optimization\n",
    "\n",
    "        # manual optimization, replaces optimizer_step(...) below\n",
    "        optimizer = self.optimizers()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step() # learning rate scheduler\n",
    "\n",
    "        self.log(\"train_loss\",loss)\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "\n",
    "    # NotImplementedError: Support for `training_epoch_end` has been removed in v2.0.0.\n",
    "    # `T5FineTuner` implements this method. You can use the `on_train_epoch_end` hook instead.\n",
    "    # To access outputs, save them in-memory as instance attributes. You can find migration examples\n",
    "    # in https://github.com/Lightning-AI/lightning/pull/16520.\n",
    "    # def training_epoch_end(self, outputs):\n",
    "    def on_train_epoch_end(self):\n",
    "        avg_train_loss = torch.stack(self.outputs).mean()\n",
    "        #avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        \n",
    "        self.log(\"avg_train_loss\", avg_train_loss)\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "\n",
    "    def on_validation_epoch_start(self) -> None:\n",
    "        super().on_validation_epoch_start()\n",
    "        self.outputs = []\n",
    "        return\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.outputs += loss.unsqueeze(0) # results\n",
    "        self.log(\"step_val_loss\", loss)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.outputs).mean()\n",
    "        #avg_loss = torch.stack([x[\"val_loss\"] for x in output_dict]).mean()\n",
    "        \n",
    "        self.log(\"val_loss\",avg_loss)\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparam.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        # \"AdamW\" was deprecated and suggested to use \"torch.optim.AdamW\" instead\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparam.learning_rate, eps=self.hparam.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    # When performing automatic optimization:\n",
    "    #    Error: The closure hasn't been executed. HINT: did you call `optimizer_closure()` in your `optimizer_step` hook?\n",
    "    #    It could also happen because the `optimizer.step(optimizer_closure)` call did not execute it internally.\n",
    "    # See also optimizer closures: https://lightning.ai/docs/pytorch/stable/common/optimization.html#use-closure-for-lbfgs-like-optimizers\n",
    "    # \n",
    "    # Replaced by training_step(...) with manual optimization.\n",
    "    def optimizer_step(self,\n",
    "                       epoch=None,\n",
    "                       batch_idx=None,\n",
    "                       optimizer=None,\n",
    "                       optimizer_idx=None,\n",
    "                       optimizer_closure=None,\n",
    "                       on_tpu=None,\n",
    "                       using_native_amp=None,\n",
    "                       using_lbfgs=None\n",
    "                       ):\n",
    "\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step() # learning rate scheduler\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(\n",
    "            self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparam.train_batch_size,\n",
    "                                drop_last=True, shuffle=True, num_workers=self.num_dataloader_workers)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) //\n",
    "             (self.hparam.train_batch_size * max(1, self.hparam.n_gpu)))\n",
    "            // self.hparam.gradient_accumulation_steps\n",
    "            * float(self.hparam.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparam.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(\n",
    "            tokenizer=self.tokenizer, type_path=\"validation\", args=self.hparam)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=self.num_dataloader_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969740d5-faba-486b-aa8e-56d815788831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"/content/drive/My Drive/Colab Notebooks/T5Ner\"\n",
    "# output_dir=\"\" defaults to /content/lightning_logs/version_n/ where n is the run number (0, 1, 2, 3...)\n",
    "OUTPUT_DIR = \"lightning_logs\" \n",
    "\n",
    "args_dict = dict(\n",
    "    data_dir=\"wikiann\", # path for data files # unused for Text2KGBench\n",
    "    output_dir=OUTPUT_DIR, # path to save the checkpoints\n",
    "    default_root_dir=OUTPUT_DIR, # path to save the checkpoints\n",
    "    model_name_or_path='google/flan-t5-small',\n",
    "    tokenizer_name_or_path='google/flan-t5-small', #t5-small\n",
    "    max_seq_length=256,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    num_dataloader_workers=1,\n",
    "    val_check_interval=0.05, # run val/checkpoint after a fixed number of training batches. See https://lightning.ai/docs/pytorch/stable/common/trainer.html#pytorch_lightning.trainer.Trainer.params.val_check_interval\n",
    "    # check_val_every_n_epoch = None # To deal with streaming data, set this to None and put an int > # training batches in val_check_interval\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False, # https://lightning.ai/docs/pytorch/stable/advanced/speed.html\n",
    "    fp_16=False, \n",
    "    #fp_16=True, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    max_grad_norm=1,\n",
    "    #max_grad_norm=0.5, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "511af0ef-14a7-48c2-855c-b35759505543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to resume training in the middle if interrupted, or to load completed model from checkpoint\n",
    "def load_model_from_checkpoint(CKPT_PATH, trainer=None):\n",
    "    model = T5FineTuner.load_from_checkpoint(CKPT_PATH)\n",
    "\n",
    "    checkpoint = torch.load(CKPT_PATH)\n",
    "\n",
    "    if trainer:\n",
    "        # restore from checkpoint/previous training progress\n",
    "        # See: https://github.com/Lightning-AI/pytorch-lightning/issues/12274\n",
    "        global_step_offset = checkpoint[\"global_step\"]\n",
    "        trainer.fit_loop.epoch_loop._batches_that_stepped = global_step_offset\n",
    "\n",
    "    # Fix for warning:\n",
    "    #     You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. \n",
    "    #     This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint \n",
    "    #     or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n",
    "    # Src: https://github.com/Lightning-AI/pytorch-lightning/issues/2798\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    elif 'state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint) # Checkpoint contains only model state dict, it's not stored in a dict\n",
    "        \n",
    "    if 'lr_scheduler_state_dict' in checkpoint:\n",
    "        model.lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "        print(\"Restored lr_scheduler_state_dict from checkpoint\")\n",
    "    if 'optimizer_state_dict' in checkpoint:\n",
    "        model.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"Restored optimizer_state_dict from checkpoint\")\n",
    "    \n",
    "    print(\"Loaded model from checkpoint:\", CKPT_PATH)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e11c50-1133-4c2f-90ad-ab32cd65a35d",
   "metadata": {},
   "source": [
    "# Fine-Tune Model with Text2KGBench\n",
    "\n",
    "This code is adapted from \"T5 NER Finetuning\" provided publicly at https://colab.research.google.com/drive/1obr78FY_cBmWY5ODViCmzdY6O1KB65Vc?usp=sharing and updated to work with pytorch_lightning v2.2.2\n",
    "\n",
    "\"T5 NER Finetuning\" says of its model:\n",
    "\"Majority of the code here is adapted from [here](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb) which uses the pytorch-lightning framework for training neural networks. T5 has shown that it can generate state of the art on many tasks as long as it can be cast as a text-to-text problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5e852-9900-40ec-bf92-94532fbe10f3",
   "metadata": {},
   "source": [
    "### Input Dataset: Tokenize and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dca88bfc-5e95-44cd-834d-1d4cea106ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='google/flan-t5-small', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "urusei yatsura 2: beautiful dreamer (japanese:, hepburn: urusei yatsura 2 by<unk>«tifuru dorä«mä<unk>) is a 1984 japanese anime fantasy comedy film, directed by mamoru oshii. </s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "director: mamoru oshii </s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# T5 Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name_or_path) #\"t5-small\")\n",
    "print(tokenizer)\n",
    "\n",
    "if TRAINING_DATASET == DatasetOptions.WIKIDATA:\n",
    "    dataset = df_wikidata_train\n",
    "elif TRAINING_DATASET == DatasetOptions.DBPEDIA:\n",
    "    dataset = df_dbpedia_train\n",
    "\n",
    "#dbpedia_train_dataset = tokenize_dataset(tokenizer=tokenizer, dataset=df_dbpedia_train, type_path='train')\n",
    "input_dataset = tokenize_dataset(tokenizer=tokenizer, dataset=dataset, type_path=\"train\")\n",
    "val_dataset = tokenize_dataset(tokenizer=tokenizer, dataset=dataset, type_path='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0866f812-281e-4adb-a8c8-4d86b0b07ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetOptions.WIKIDATA\n"
     ]
    }
   ],
   "source": [
    "# below: original code adapted from \"T5 NER Finetuning\"\n",
    "# moved into tokenize_data(tokenizer, dataset, type_path)\n",
    "\n",
    "#input_dataset = CustomDataset(tokenizer=tokenizer, dataset=dataset, type_path='train')\n",
    "#val_dataset = CustomDataset(tokenizer=tokenizer, dataset=dataset, type_path='val')\n",
    "#for i in range(len(input_dataset)):\n",
    "#    _ = input_dataset[i]\n",
    "#data = input_dataset[0]\n",
    "\n",
    "#print(tokenizer.decode(data[\"source_ids\"], skip_special_tokens=False))\n",
    "#print(tokenizer.decode(data[\"target_ids\"], skip_special_tokens=False))\n",
    "\n",
    "# dict of tensors\n",
    "print(TRAINING_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0542bebb-6336-498c-9d4d-ca2c9566ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# called by LightningModule internally\n",
    "def get_dataset(tokenizer, type_path, args):\n",
    "    tokenizer.max_length = args.max_seq_length\n",
    "    tokenizer.model_max_length = args.max_seq_length\n",
    "    #if type_path == \"validation\":\n",
    "    #    return val_dataset\n",
    "    #dataset = load_dataset(args.data_dir, \"en\")\n",
    "    return input_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb45cb7-41f9-4a4b-9db9-091bba386280",
   "metadata": {},
   "source": [
    "## Fine-Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf78bf1b-4787-4cf4-bafd-fe46f4c874f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p t5_ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308ff93-757c-42a4-b7c2-5b30086e7f88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Set Up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30078e03-f023-4d2b-aa12-7b05f6f9e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS_TO_SAVE_AFTER = 1\n",
    "\n",
    "if TRAINING_DATASET == DatasetOptions.WIKIDATA:\n",
    "    NUM_STEPS_TO_SAVE_AFTER = 37 # divides evenly into df_wikidata_train (37/666 = 18)\n",
    "elif TRAINING_DATASET == DatasetOptions.DBPEDIA:\n",
    "    NUM_STEPS_TO_SAVE_AFTER = 37 # divides evenly into df_dbpedia_train (37/666 = 18)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d261a894-6fb8-480d-8df2-75d75f6e5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingCallback(pl.Callback):\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    print(\"Logging validation results\")\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "        \n",
    "      # Log results\n",
    "      output_val_results_file = os.path.join(args.output_dir, \"val_results.txt\")\n",
    "      with open(output_val_results_file, \"a\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    print(\"Logging testing results\")\n",
    "    logger.info(\"***** Test results *****\")\n",
    "\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "      output_test_results_file = os.path.join(args.output_dir, \"test_results.txt\")\n",
    "      with open(output_test_results_file, \"a\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85ec1eac-0bee-4b52-8a67-fa989fb69f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints, pl.callbacks.ModelCheckpoint\n",
    "# https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html\n",
    "training_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=args.output_dir,\n",
    "    filename=\"{epoch}-{step}-{train_loss:.2f}\", # defaults to None or '{epoch}-{step}'\n",
    "    monitor=\"train_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=-1, #save all of them\n",
    "    save_on_train_epoch_end=True,\n",
    "    every_n_train_steps=NUM_STEPS_TO_SAVE_AFTER # checkpoint every n training steps\n",
    ")\n",
    "epoch_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=args.output_dir,\n",
    "    filename=\"{epoch}-{step}-{val_loss:.2f}\", # defaults to None or '{epoch}-{step}'\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=-1, #save all of them\n",
    "    every_n_epochs=NUM_EPOCHS_TO_SAVE_AFTER, # checkpoint every n epochs\n",
    ")\n",
    "logging_callback = LoggingCallback()\n",
    "\n",
    "# old\n",
    "#checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "#    filename=args.output_dir+\"/checkpoint.pth\",\n",
    "#    monitor=\"val_loss\",\n",
    "#    mode=\"min\",\n",
    "#    save_top_k=5\n",
    "\n",
    "# TypeError: Trainer.__init__() got an unexpected keyword argument 'gpus'\n",
    "# TypeError: Trainer.__init__() got an unexpected keyword argument 'checkpoint_callback'\n",
    "# https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "\n",
    "# error with dbpedia_train_dataset:\n",
    "#   self.trainer.num_training_batches == 0\n",
    "#   `Trainer.fit` stopped: No training batches.\n",
    "\n",
    "train_params = dict(\n",
    "    #accumulate_grad_batches=args.gradient_accumulation_steps, # not supported with manual optmization\n",
    "    #gpus=args.n_gpu,                                          # Trainer: unexpected keyword argument\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,                                # initially commented out\n",
    "    precision=32,\n",
    "      # precision='bf16-mixed' if args.fp_16 else 32,\n",
    "      # `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
    "      # You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
    "    #amp_level=args.opt_level,                                 # initially commented out\n",
    "    #gradient_clip_val=args.max_grad_norm,                     # not supported with manual optimization\n",
    "    gradient_clip_val=0,\n",
    "    #checkpoint_callback=checkpoint_callback,                  # Trainer: unexpected keyword argument\n",
    "    callbacks=[training_checkpoint_callback, epoch_checkpoint_callback, logging_callback],\n",
    "    #num_sanity_val_steps=0,\n",
    "      # skip the sanity check and go straight to training\n",
    "      # removed; was causing the error: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
    "    # accelerator=\"gpu\", devices=1                             # run on 1 gpu - No supported gpu backend found!\n",
    "    # check_val_every_n_epoch=1/18 # deprecated for val_check_interval between 0 and 1\n",
    "    #val_check_interval=1\n",
    "        # set to less than 1, e.g. 1/18 to validate multiple times in an epoch.\n",
    "        # `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a42f40-733b-439e-bdcc-9f84cb0950b7",
   "metadata": {},
   "source": [
    "### Load Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0cc21cdb-ec01-4add-accf-4eb421cccb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The checkpoint to load the model from. Set to None to load from scratch.\n",
    "#  e.g. \"lightning_logs/version_26/epoch=1-step=1089-train_loss=0.48.ckpt\"\n",
    "# Model fine-tuned on Wikidata:\n",
    "#  version 33: CKPT_PATH = \"lightning_logs/version_32/epoch=0-step=666-val_loss=0.34.ckpt\"\n",
    "#  version 34: CKPT_PATH = \"lightning_logs/version_33/epoch=2-step=1998-val_loss=0.25.ckpt\"\n",
    "#  version 36: CKPT_PATH = \"lightning_logs/version_34/epoch=3-step=2072-train_loss=0.35.ckpt\"\n",
    "# Model fine-tuned on DBPedia:\n",
    "# version 37: (from scratch)\n",
    "\n",
    "CKPT_PATH = None\n",
    "#CKPT_PATH = \"lightning_logs/version_34/epoch=3-step=2072-train_loss=0.35.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "436d7240-d4f7-4a72-9316-ce697c4c2b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initiated for...\n",
      "  Model: google/flan-t5-small\n",
      "  Dataset: DatasetOptions.DBPEDIA\n",
      "  Checkpoint: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 77.0 M\n",
      "-----------------------------------------------------\n",
      "77.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "77.0 M    Total params\n",
      "307.845   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging validation results\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85a36d083f1413ca071e8cf7ae2f598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging validation results\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging validation results\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     model \u001b[38;5;241m=\u001b[39m T5FineTuner(args)\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded from scratch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:269\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# update `is_last_batch` again after dataloader_iter was fetched in `training_step()`\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m--> 269\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_batch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_output, batch, batch_idx)\n\u001b[0;32m    271\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_batch_end()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:208\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[1;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 208\u001b[0m             fn(trainer, trainer\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:315\u001b[0m, in \u001b[0;36mModelCheckpoint.on_train_batch_end\u001b[1;34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_time_checked \u001b[38;5;241m=\u001b[39m now\n\u001b[0;32m    314\u001b[0m monitor_candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monitor_candidates(trainer)\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_topk_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_last_checkpoint(trainer, monitor_candidates)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:384\u001b[0m, in \u001b[0;36mModelCheckpoint._save_topk_checkpoint\u001b[1;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(m)\n\u001b[0;32m    383\u001b[0m         warning_cache\u001b[38;5;241m.\u001b[39mwarn(m)\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_monitor_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:704\u001b[0m, in \u001b[0;36mModelCheckpoint._save_monitor_checkpoint\u001b[1;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_monitor_top_k(trainer, current):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_best_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    706\u001b[0m     epoch \u001b[38;5;241m=\u001b[39m monitor_candidates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:756\u001b[0m, in \u001b[0;36mModelCheckpoint._update_best_and_save\u001b[1;34m(self, current, trainer, monitor_candidates)\u001b[0m\n\u001b[0;32m    751\u001b[0m     step \u001b[38;5;241m=\u001b[39m monitor_candidates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    752\u001b[0m     rank_zero_info(\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, global step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    754\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (best \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), saving model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m as top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    755\u001b[0m     )\n\u001b[1;32m--> 756\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m del_filepath \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_remove_checkpoint(trainer, del_filepath, filepath):\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_checkpoint(trainer, del_filepath)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:389\u001b[0m, in \u001b[0;36mModelCheckpoint._save_checkpoint\u001b[1;34m(self, trainer, filepath)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_global_step_saved \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mglobal_step\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_checkpoint_saved \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1381\u001b[0m, in \u001b[0;36mTrainer.save_checkpoint\u001b[1;34m(self, filepath, weights_only, storage_options)\u001b[0m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving a checkpoint is only possible if a model is attached to the Trainer. Did you call\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `Trainer.save_checkpoint()` before calling `Trainer.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mfit,validate,test,predict}`?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1379\u001b[0m     )\n\u001b[0;32m   1380\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mdump_checkpoint(weights_only)\n\u001b[1;32m-> 1381\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer.save_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:491\u001b[0m, in \u001b[0;36mStrategy.save_checkpoint\u001b[1;34m(self, checkpoint, filepath, storage_options)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_global_zero:\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning_fabric\\plugins\\io\\torch_io.py:58\u001b[0m, in \u001b[0;36mTorchCheckpointIO.save_checkpoint\u001b[1;34m(self, checkpoint, path, storage_options)\u001b[0m\n\u001b[0;32m     56\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path)\n\u001b[0;32m     57\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43m_atomic_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:80\u001b[0m, in \u001b[0;36m_atomic_save\u001b[1;34m(checkpoint, filepath)\u001b[0m\n\u001b[0;32m     78\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(checkpoint, bytesbuffer)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fsspec\u001b[38;5;241m.\u001b[39mopen(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytesbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fsspec\\implementations\\local.py:373\u001b[0m, in \u001b[0;36mLocalFileOpener.write\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "print(f\"Training initiated for...\\n  Model: {args.model_name_or_path}\\n  Dataset: {TRAINING_DATASET}\\n  Checkpoint: {CKPT_PATH}\")\n",
    "\n",
    "trainer = pl.Trainer(**train_params)\n",
    "\n",
    "if CKPT_PATH:\n",
    "    model = load_model_from_checkpoint(CKPT_PATH, trainer)\n",
    "\n",
    "    # RuntimeError: T5FineTuner is not attached to a `Trainer\n",
    "    # lightning  model object has no attribute 'lr_scheduler'\n",
    "    # etc.\n",
    "    #if model.trainer.lr_schedulers: #config.train.lrScheduler.name == 'StepLR':\n",
    "    #    model.trainer.lr_schedulers.last_epoch = checkpoint['epoch']\n",
    "    #    print(\"Restored lr_scheduler epoch from checkpoint\")\n",
    "    \n",
    "    trainer.fit(model, ckpt_path=CKPT_PATH)\n",
    "else:\n",
    "    model = T5FineTuner(args)\n",
    "    trainer.fit(model)\n",
    "    print(\"Loaded from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83809521-0d45-472c-8777-98e6992d8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "#manually checkpoint the model after training\n",
    "trainer.save_checkpoint(\"lightning_logs/final.ckpt\")\n",
    "print(\"Saved\")\n",
    "\n",
    "\n",
    "# Read checkpoint information\n",
    "#checkpoint = torch.load(CKPT_PATH)\n",
    "#global_step_offset = checkpoint[\"global_step\"]\n",
    "#print(global_step_offset)\n",
    "#print(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e1f4d-5968-4999-a3ed-09f075475e83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# (old, moved) Load the Stored Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d25e75-c0c6-4278-bb72-84dd7555bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CKPT_PATH = \"lightning_logs/version_30/final.ckpt\"\n",
    "checkpoint = torch.load(CKPT_PATH)\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2d84e-fac3-4127-87b1-7472e80d5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5FineTuner.load_from_checkpoint(CKPT_PATH)\n",
    "print(\"Done\")\n",
    "#print(model.keys()) #'T5FineTuner' object has no attribute 'keys'\n",
    "\n",
    "#model.eval() # disable randomness, dropout, etc...\n",
    "#y_hat = model(x) # predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8e4bbb2-4907-4083-ace0-c45c0876fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation_dataset = input_dataset\n",
    "\n",
    "dbpedia_test_dataset = CustomDataset(tokenizer=tokenizer, dataset=df_dbpedia_test, type_path='test')\n",
    "wikidata_test_dataset = CustomDataset(tokenizer=tokenizer, dataset=df_wikidata_test, type_path='test')\n",
    "evaluation_dataset = wikidata_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7b38582-9126-41af-b06a-c29fc1b2e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: \"little bad girl\" is a single by french dj david guetta, featuring vocals from english\n",
      "recording artist taio cruz and american rapper ludacris.\n",
      "\n",
      "Actual Entities: performer: david guetta, performer: ludacris, performer: taio cruz, lyrics by: david guetta, producer: david guetta\n",
      "Predicted Entities: performer: taio cruz\n",
      "=====================================================================\n",
      "\n",
      "text: the novel is set during world war ii, with most of the action occurring on or near a fictional\n",
      "army air forces base in central florida.\n",
      "\n",
      "Actual Entities: genre: novel, narrative location: florida\n",
      "Predicted Entities: narrative location: central florida\n",
      "=====================================================================\n",
      "\n",
      "text: mandubracius or mandubratius was a king of the trinovantes of south-eastern britain in the 1st\n",
      "century bc.\n",
      "\n",
      "Actual Entities: ethnic group: trinovantes\n",
      "Predicted Entities: languages spoken, written or signed: bc\n",
      "=====================================================================\n",
      "\n",
      "text: tomoyuki yamashita ( , yamashita tomoyuki, 8 november 1885 - 23 february 1946; also called\n",
      "tomobumi yamashita) was a japanese general of the imperial japanese army during world war ii.\n",
      "\n",
      "Actual Entities: military branch: imperial japanese army\n",
      "Predicted Entities: military branch: japanese army\n",
      "=====================================================================\n",
      "\n",
      "text: a founder of the democratic party, martin van buren had previously served as the ninth\n",
      "governor of new york, the tenth united states secretary of state, and the eighth vice president of\n",
      "the united states.\n",
      "\n",
      "Actual Entities: position held: united states secretary of state, position held: vice president of the united states, position held: president of the united states, position held: governor of new york\n",
      "Predicted Entities: president: martin van buren\n",
      "=====================================================================\n",
      "\n",
      "text: the journal of artificial societies and social simulation (jasss) is a quarterly peer-reviewed\n",
      "academic journal created by nigel gilbert (university of surrey).\n",
      "\n",
      "Actual Entities: editor: nigel gilbert, publisher: university of surrey\n",
      "Predicted Entities: editor: nigel gilbert\n",
      "=====================================================================\n",
      "\n",
      "text: the film garnered forster a nomination for the academy award for best supporting actor and\n",
      "golden globe award nominations for jackson and grier.\n",
      "\n",
      "Actual Entities: nominated for: academy award for best supporting actor\n",
      "Predicted Entities: nominated for: golden globe award for supporting actor\n",
      "=====================================================================\n",
      "\n",
      "text: the short is directed by william hanna and joseph barbera, composed by scott bradley, and\n",
      "animated by ray patterson, irven spence, pete burness, and kenneth muse.\n",
      "\n",
      "Actual Entities: director: joseph barbera, director: william hanna, screenwriter: joseph barbera, screenwriter: william hanna\n",
      "Predicted Entities: director: scott bradley\n",
      "=====================================================================\n",
      "\n",
      "text: the wedding of valeni was produced by wiener kunstfilm, the leading austrian studio of the\n",
      "era.\n",
      "\n",
      "Actual Entities: production company: wiener kunstfilm\n",
      "Predicted Entities: production company: wiener kunstfilm\n",
      "=====================================================================\n",
      "\n",
      "text: in 1990, capitol records re-issued stack-o-tracks on cd, and again in 2001 - both releases\n",
      "without the booklet that accompanied the vinyl edition.\n",
      "\n",
      "Actual Entities: record label: capitol records\n",
      "Predicted Entities: record label: capitol records\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "dataloader = DataLoader(evaluation_dataset, batch_size=32, num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "model = model.to(\"cpu\")\n",
    "outputs = []\n",
    "targets = []\n",
    "texts = []\n",
    "for batch in dataloader:\n",
    "\n",
    "    outs = model.model.generate(input_ids=batch['source_ids'],\n",
    "                                attention_mask=batch['source_mask'])\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    text = [tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    texts.extend(text)\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    break\n",
    "\n",
    "for i in range(10):\n",
    "    c = texts[i]\n",
    "    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual Entities: %s\" % target[i])\n",
    "    print(\"Predicted Entities: %s\" % outputs[i])\n",
    "    print(\"=====================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce445e3-6a68-428f-a8b1-e56c451cc6a8",
   "metadata": {},
   "source": [
    "## Calculate Metrics\n",
    "The following code calculates metrics for the WikiANN dataset, which I am not using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a05a27cf-2448-424c-b2d1-5fbbe8da6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sub_list(sl, l):\n",
    "    results = []\n",
    "    sll = len(sl)\n",
    "    for ind in (i for i, e in enumerate(l) if e == sl[0]):\n",
    "        if l[ind:ind+sll] == sl:\n",
    "            results.append((ind, ind+sll-1))\n",
    "    return results\n",
    "\n",
    "def generate_label(input: str, target: str):\n",
    "    mapper = {'O': 0, 'B-DATE': 1, 'I-DATE': 2, 'B-PER': 3,\n",
    "              'I-PER': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-LOC': 7, 'I-LOC': 8}\n",
    "    inv_mapper = {v: k for k, v in mapper.items()}\n",
    "\n",
    "    input = input.split(\" \")\n",
    "    target = target.split(\"; \")\n",
    "\n",
    "    init_target_label = [mapper['O']]*len(input)\n",
    "\n",
    "    for ent in target:\n",
    "        ent = ent.split(\": \")\n",
    "        try:\n",
    "            sent_end = ent[1].split(\" \")\n",
    "            index = find_sub_list(sent_end, input)\n",
    "        except:\n",
    "            continue\n",
    "        # print(index)\n",
    "        try:\n",
    "            init_target_label[index[0][0]] = mapper[f\"B-{ent[0].upper()}\"]\n",
    "            for i in range(index[0][0]+1, index[0][1]+1):\n",
    "                init_target_label[i] = mapper[f\"I-{ent[0].upper()}\"]\n",
    "        except:\n",
    "            continue\n",
    "    init_target_label = [inv_mapper[j] for j in init_target_label]\n",
    "    return init_target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20d0e6ba-9dbc-49bb-9a03-0f3735a4e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py\", line 282, in _close\n",
      "    _CloseHandle(self._handle)\n",
      "OSError: [WinError 6] The handle is invalid\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "  0%|                                                                                      | 0/127 [00:00<?, ?it/s]C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 127/127 [17:05<00:00,  8.08s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# KeyError: 'rel_label'\n",
    "test_dataset = CustomDataset(tokenizer=tokenizer, dataset=df_wikidata_test, type_path='test') #WikiAnnDataset(tokenizer=tokenizer, dataset=dataset, type_path='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                             num_workers=2, shuffle=True)\n",
    "model.model.eval()\n",
    "#model = model.to(\"cuda\") # cuda not supported on my machine\n",
    "outputs = []\n",
    "targets = []\n",
    "all_text = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['source_ids'] #.to(\"cuda\")\n",
    "    attention_mask = batch['source_mask'] #.to(\"cuda\")\n",
    "    outs = model.model.generate(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "    dec = [tokenizer.decode(ids, skip_special_tokens=True,\n",
    "                            clean_up_tokenization_spaces=False).strip() for ids in outs]\n",
    "    target = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"target_ids\"]]\n",
    "    texts = [tokenizer.decode(ids, skip_special_tokens=True,  clean_up_tokenization_spaces=False).strip()\n",
    "                for ids in batch[\"source_ids\"]]\n",
    "    true_label = [generate_label(texts[i].strip(), target[i].strip()) if target[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "    pred_label = [generate_label(texts[i].strip(), dec[i].strip()) if dec[i].strip() != 'none' else [\n",
    "        \"O\"]*len(texts[i].strip().split()) for i in range(len(texts))]\n",
    "\n",
    "    outputs.extend(dec)\n",
    "    targets.extend(target)\n",
    "    true_labels.extend(true_label)\n",
    "    pred_labels.extend(pred_label)\n",
    "    all_text.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08c3f152-180d-4a43-92e9-d80b86b59782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a cauldron of witches is a 1988 anthology of 12 fairy tales from around the world that have been collected and retold by ruth manning-sanders.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f72033b-fb8f-40bd-b982-8245d16dd095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\lawfu\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\seqeval\\9642e8a602ba52bd4d8baee1d13b2deb8247d3719041cf02b40bf8367a05aef5 (last modified on Wed Apr 24 13:57:23 2024) since it couldn't be found locally at seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Text:  pour la suite du monde (also known as for those who will follow; of whales, the moon, and men, or the moontrap in english) is a 1963 canadian documentary film directed by michel brault, marcel carri re and pierre perrault.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "1\n",
      "Text:  a cauldron of witches is a 1988 anthology of 12 fairy tales from around the world that have been collected and retold by ruth manning-sanders.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "2\n",
      "Text:  warcraft iii: the frozen throne is the expansion pack for warcraft iii: reign of chaos, a real-time strategy video game by blizzard entertainment.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "3\n",
      "Text:  during a 21-year professional career, sebastiano rossi appeared in 346 serie a games, most notably representing a.c. milan (12 seasons) with which he won 12 major titles, including five national championships and the 1994 champions league.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "4\n",
      "Text:  the assignation, or love in a nunnery is a restoration comedy written by john dryden.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "5\n",
      "Text:  microsoft ended extended support for windows 95 on december 31, 2001.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "6\n",
      "Text:  vasily stepanovich zavoyko (russian: ; 5 july 1809 - 16 february 1898) was an admiral in the russian navy.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "7\n",
      "Text:  the music was composed by the german immigrant fredrik pacius, with original swedish words by johan ludvig runeberg, and with this music maamme was performed for the first time on 13 may 1848.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "8\n",
      "Text:  the founding editor-in-chief was philip bourne (university of virginia) and the current one is ruth nussinov (tel aviv university).\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n",
      "9\n",
      "Text:  radiogatn is a cryptographic hash primitive created by guido bertoni, joan daemen, michal peeters, and gilles van assche.\n",
      "Predicted Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Token Class:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\lawfu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall_precision': 0.0, 'overall_recall': 0.0, 'overall_f1': 0.0, 'overall_accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. \n",
    "#   Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
    "# FutureWarning: The repository for seqeval contains custom code which must be executed to correctly \n",
    "#   load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
    "#   You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
    "#   Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
    "#metric = load_metric(\"seqeval\")\n",
    "metric = load_metric(\"seqeval\", trust_remote_code=True)\n",
    "\n",
    "num_to_check = 10\n",
    "for i in range(num_to_check):\n",
    "    print(i)\n",
    "    print(f\"Text:  {all_text[i]}\")\n",
    "    print(f\"Predicted Token Class:  {pred_labels[i]}\")\n",
    "    print(f\"True Token Class:  {true_labels[i]}\")\n",
    "    print(\"=====================================================================\\n\")\n",
    "\n",
    "print(metric.compute(predictions=pred_labels, references=true_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c828e-ab3a-48df-8d3e-4eb300f46f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
